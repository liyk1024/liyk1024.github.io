<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Django的MFA验证码接口]]></title>
    <url>%2F2019%2F07%2F25%2FDjango%E7%9A%84MFA%E9%AA%8C%E8%AF%81%E7%A0%81%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[背景 增加双因子认证，提高网站登录的安全性。利用谷歌身份验证器绑定密钥，从而进行动态MFA验证。 原理核心内容 Google Authenticator采用的算法是TOTP（Time-Based One-Time Password基于时间的一次性密码），其核心内容包括以下三点： 一个共享密钥 当前时间输入 一个签名函数 加密原理和步骤 Step1：base32 secret K：共享密钥，在Google Authenticator中是通过将一段字符串进行base32解码成bytes得到的。但由于此密钥在不够32位或超过32位时会用’=’表示，故用的pyotp随机生成的密钥。 12Secret = pyotp.random_base32()K = base64.b32decode(Secret, True) Step2：get current timestamp C：计数器，通过当前时间戳除以30然后将得到的整数转换成一个大端序的字节。123# int(time.time()) // 30 到当前经历了多少个30秒# 将间隔时间转为big-endian(大端序)并且为长整型的字节C = struct.pack(&quot;&gt;Q&quot;, int(time.time()) // 30) Step3：start hmac-sha1 H：将K和C做HMAC-SHA-1加密然后以字节方式保存，因为后期需要进行与运算，而str是不能和int进行与运算的。12345# hmac = SHA1(secret + SHA1(secret + input))# 为了方便演示，将字节转换成了字符串显示H = hmac.new(K, C, hashlib.sha1).digest()# 取出最后一位和数字15做与运算O = H[19] &amp; 15 Step4：get DynamicPasswd 通过计算出来的O在H中取出4个16进制的字节，然后将字节转换成正整数，因转换后的正整数是放在数组里面的，所以需要使用[0]取出。最后与一个全为1的二进制与运算然后与10^6做取余运算，最终会得到一个6位数的TOTP12345DynamicPasswd = str((struct.unpack(&quot;&gt;I&quot;, H[O:O + 4])[0] &amp; 0x7fffffff) % 1000000) # struct.unpack(&apos;&gt;I&apos;,h[o:o+4])[0] :转为big-endian(大端序)并且不为负数的数字(整数),因为转换完是一个数组,类似&quot;(2828101188,)&quot;,所以需要[0]取出# h[o:o+4] :取其中4个字节 o=10 则取索引分别为 10,11,12,13的字节# &amp; 0x7fffffff = 11111111 :与字节转换的数字做与运算# % 1000000 :得出的数字与1000000相除然后取余 Step5：get MFA 最后计算出的6位数字最左边的一位可能为0，所以需要判断如果DynamicPasswd得到的是一个5位数的数字，那就在最左边加上一个0。1TOTP = str(0) + str(DynamicPasswd) if len(DynamicPasswd) &lt; 6 else DynamicPasswd 实现步骤 1.使用python的pyotp模块生成谷歌认证需要的密钥 2.根据密钥生成二维码图片以及计算出6位动态验证码 3.使用谷歌的身份验证器app，扫描二维码或者手动输入密钥 4.平台二次认证通过对输入的动态验证码进行校验 相关代码12345678910111213141516171819202122232425262728293031323334353637383940414243import base64, time, struct, hmac, hashlibimport pyotpfrom qrcode import QRCodefrom qrcode import constantsname = &apos;user01&apos;+&apos;:SmartMS&apos;# 利用参数secretKey,计算Google Authenticator 6位动态码。def getMFACode(Secret): print(&apos;MFA密钥:&#123;&#125;&apos;.format(Secret)) K = base64.b32decode(Secret, True) C = struct.pack(&quot;&gt;Q&quot;, int(time.time()) // 30) H = hmac.new(K, C, hashlib.sha1).digest() O = H[19] &amp; 15 # bin(15)=00001111=0b1111 DynamicPasswd = str((struct.unpack(&quot;&gt;I&quot;, H[O:O + 4])[0] &amp; 0x7fffffff) % 1000000) TOTP = str(0) + str(DynamicPasswd) if len(DynamicPasswd) &lt; 6 else DynamicPasswd print(&apos;动态MFA:&#123;&#125;&apos;.format(TOTP)) return TOTPdef getMFAImg(name,Secret): # otpauth://totp/ 固定格式 # name：标识符信息，issuer：发行信息 url = &quot;otpauth://totp/&quot; + name + &quot;?secret=%s&quot; % Secret + &quot;&amp;issuer=Anchnet&quot; qr = QRCode(version=1, error_correction=constants.ERROR_CORRECT_L,box_size=6,border=4) qr.add_data(url) qr.make(fit=True) img = qr.make_image() # img.show()def checkCode(Secret): code = int(input(&apos;输入验证码:&apos;)) t = pyotp.TOTP(Secret) result = t.verify(code) msg = result if result is True else False print(&apos;验证码验证&#123;&#125;&apos;.format(msg)) return msgif __name__ == &apos;__main__&apos;: Secret = pyotp.random_base32() # Secret = &apos;UFB6R5QKLPV7FGIU&apos; getMFACode(Secret) Secret = getMFAImg(name,Secret) # checkCode(Secret) 封装为接口 views.py 123456789101112131415161718192021222324from utils import restful # 自定义的restfulimport base64, time, struct, hmac, hashlibimport pyotpfrom qrcode import QRCodefrom qrcode import constantsdef getMFAinfo(request): name = request.GET[&apos;name&apos;] + &apos;:SmartMS&apos; # Secret = request.GET[&apos;secret&apos;] Secret = pyotp.random_base32() K = base64.b32decode(Secret, True) C = struct.pack(&quot;&gt;Q&quot;, int(time.time()) // 30) H = hmac.new(K, C, hashlib.sha1).digest() O = H[19] &amp; 15 # bin(15)=00001111=0b1111 DynamicPasswd = str((struct.unpack(&quot;&gt;I&quot;, H[O:O + 4])[0] &amp; 0x7fffffff) % 1000000) TOTP = str(0) + str(DynamicPasswd) if len(DynamicPasswd) &lt; 6 else DynamicPasswd url = &quot;otpauth://totp/&quot; + name + &quot;?secret=%s&quot; % Secret + &quot;&amp;issuer=Anchnet&quot; qr = QRCode(version=1, error_correction=constants.ERROR_CORRECT_L, box_size=6, border=4) qr.add_data(url) qr.make(fit=True) img = qr.make_image() codeinfo = &#123;&quot;name&quot;:name, &quot;MFAcode&quot;:TOTP, &quot;Secret&quot;:Secret, &quot;QRurl&quot;:url&#125; return restful.result(message=&quot;获取成功&quot;,data=codeinfo) 主urls.py 12345678from django.urls import path,includefrom apps.news import viewsurlpatterns = [ ... path(&apos;account/&apos;,include(&quot;apps.xfzauth.urls&quot;)), ...] apps的urls.py 12345678910from django.urls import pathfrom . import viewsapp_name = &apos;xfzauth&apos;urlpatterns = [ ... path(&apos;code/&apos;,views.getMFAinfo,name=&apos;code&apos;), ...] 测试 验证码生成测试 接口测试]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MFA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop集群搭建]]></title>
    <url>%2F2019%2F07%2F19%2FHadoop%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[基础配置 三台机器上编辑/etc/hosts配置文件，修改主机名。 三台机器在集群中担任的角色： master:NameNode、DataNode、ResourceManager、NodeManager node1:DataNode、NodeManager node2:DataNode、NodeManager 配置ssh免密登录 1234# 三台机器上分别执行，互相免密登录ssh-keygen -t rsassh-copy-id -i ~/.ssh/id_rsa.pub node1ssh-copy-id -i ~/.ssh/id_rsa.pub node2 安装JDK 1234# 官网下载https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.htmlhttp://anchnet-script.oss-cn-shanghai.aliyuncs.com/oracle/jdk-8u171-linux-x64.rpmyum localinstall jdk-8u171-linux-x64.rpm -y 配置java环境变量 12345678# 三台均操作vim /etc/profileJAVA_HOME=/usr/java/jdk1.8.0_171-amd64JAVA_BIN=/usr/java/jdk1.8.0_171-amd64/binJRE_HOME=/usr/java/jdk1.8.0_171-amd64/jreexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH# source命令加载配置文件，让其生效source /etc/profile Hadpop配置分发 下载hadoop 12https://www.apache.org/dist/hadoop/common/wget https://www.apache.org/dist/hadoop/common/hadoop-2.6.5/hadoop-2.6.5.tar.gz 解压 1tar -zxvf hadoop-2.6.5.tar.gz -C /data/modules 查看hadoop目录结构 1cd /data/modules/hadoop-2.6.5/ bin目录存放可执行文件 etc目录存放配置文件 sbin目录下存放服务的启动命令 share目录下存放jar包与文档 配置hadoop环境变量 1234vim ~/.bash_profileexport HADOOP_HOME=/data/modules/hadoop-2.6.5/export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATHsource !$ 编辑hadoop配置文件 编辑etc/core-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://10.234.2.169:8020&lt;/value&gt; # 指定默认的访问地址以及端口号 &lt;/property&gt; 编辑etc/hdfs-site.xml 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/data/hadoop/app/tmp/dfs/name&lt;/value&gt; # namenode临时文件所存放的目录 &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/data/hadoop/app/tmp/dfs/data&lt;/value&gt; # datanode临时文件所存放的目录 &lt;/property&gt; 创建数据目录 12mkdir -p /data/hadoop/app/tmp/dfs/namemkdir -p /data/hadoop/app/tmp/dfs/data 编辑etc/yarn-site.xml 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 编辑etc/mapred-site.xml 123456789cp mapred-site.xml.template mapred-site.xmlvim !$&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; # 指定mapreduce运行在yarn框架上 &lt;/property&gt;&lt;/configuration&gt; 配置从节点的主机名etc/slaves 12node1node2 2台node节点也需创建对应安装目录，环境变量配置等 123456scp ~/.bash_profile node1:~/.bash_profilescp * node1:/data/modules/hadoop-2.6.5/etc/hadoop/# 2台节点上如下操作source ~/.bash_profilemkdir -p /data/hadoop/app/tmp/dfs/namemkdir -p /data/hadoop/app/tmp/dfs/data Hadoop格式化及启停 对NameNode做格式化，只需要在master上执行即可 12[root@master hadoop]# hdfs namenode -format# 格式化是对HDFS这个分布式文件系统中的DataNode进行分块，统计所有分块后的初始元数据的存储在NameNode中 格式化之后就可以启动Hadoop集群 12# sbin目录下,执行脚本，执行后要输入master服务器的密码[root@master hadoop]# ./start-all.sh 查看机器进程 master 123456789101112131415161718[root@master sbin]# jps19237 SecondaryNameNode22231 NodeManager21978 ResourceManager19019 NameNode30941 Jps21327 DataNode# 如果master上的某些服务进程未启动，需要再次手动执行脚本启动# 启动NameNodesbin/hadoop-daemon.sh start namenode# 启动DataNodesbin/hadoop-daemon.sh start datanode# 启动SecondaryNameNodesbin/hadoop-daemon.sh start secondarynamenode# 启动Resourcemanagersbin/yarn-daemon.sh start resourcemanager# 启动nodemanagersbin/yarn-daemon.sh start nodemanager node1234[root@node1 ~]# jps25827 Jps18742 DataNode20583 NodeManager 访问测试 访问主节点 50070 访问主节点 YARN的web页面 点击“Active Nodes”查看存活的节点 执行命令 12345hdfs dfs -ls /hdfs dfs -mkdir /test123hdfs dfs -put ./test.sh /test123# 然后去其他节点查看，不同的节点，访问的数据也是一样的hdfs dfs -ls / 运行MapReduce Job 在Hadoop的share目录里，自带了一些jar包，里面带有一些mapreduce实例小例子。位置在/data/modules/hadoop-2.6.5/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar 创建输入目录 1234567bin/hdfs dfs -mkdir -p /test1/input# 原始文件[root@master hadoop-2.6.5]# cat /data/hadoop/test1.input hadoop hadoop hivemapreduce hive stormsqoop hadoop hivespark hadoop hbase 上传到HDFS的/test1/input目录中 运行WordCount MapReduce Job1[root@master hadoop-2.6.5]# bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar wordcount /test1/input /test1/output YARN web控制台查看 查看输出结果 123456789101112131415[root@master hadoop-2.6.5]# hdfs dfs -ls /test1/outputFound 2 items-rw-r--r-- 3 root supergroup 0 2018-12-13 15:22 /test1/output/_SUCCESS-rw-r--r-- 3 root supergroup 60 2018-12-13 15:22 /test1/output/part-r-00000# output目录中有两个文件，_SUCCESS文件是空文件，有这个文件说明Job执行成功。part-r-00000文件是结果文件，其中-r-说明这个文件是Reduce阶段产生的结果。一个reduce会产生一个part-r-开头的文件。# 查看执行结果[root@master hadoop-2.6.5]# hdfs dfs -cat /test1/output/part-r-00000hadoop 4hbase 1hive 3mapreduce 1spark 1sqoop 1storm 1# 结果是按照键值排序好的 停止Hadoop 123456789# 主节点上执行 stop-all.sh，如果进程未全部终止，就执行如下脚本对应停止。[root@master hadoop-2.6.5]# sbin/hadoop-daemon.sh stop namenodestopping namenode[root@master hadoop-2.6.5]# sbin/hadoop-daemon.sh stop datanodestopping datanode[root@master hadoop-2.6.5]# sbin/yarn-daemon.sh stop resourcemanagerstopping resourcemanager[root@master hadoop-2.6.5]# sbin/yarn-daemon.sh stop nodemanagerstopping nodemanager 开启历史服务 Hadoop开启历史服务可以在web页面上查看Yarn上执行job情况的详细信息。可以通过历史服务器查看已经运行完的Mapreduce作业记录，比如用了多少个Map、用了多少个Reduce、作业提交时间、作业启动时间、作业完成时间等信息。 开启日志聚集1234567891011# Hadoop默认是不启用日志聚集的。在yarn-site.xml文件里配置启用日志聚集。&lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;106800&lt;/value&gt;&lt;/property&gt;# yarn.log-aggregation-enable:是否启用日志聚集功能。# yarn.log-aggregation.retain-seconds：设置日志保留时间，单位是秒。 将配置文件发布到其他节点： 12scp etc/hadoop/yarn-site.xml node1:/data/modules/hadoop-2.6.5/etc/hadoop/scp etc/hadoop/yarn-site.xml node2:/data/modules/hadoop-2.6.5/etc/hadoop/ 重启Yarn进程和HistoryServer进程 1234sbin/stop-yarn.shsbin/start-yarn.shsbin/mr-jobhistory-daemon.sh stop historyserversbin/mr-jobhistory-daemon.sh start historyserver 测试日志聚集运行一个demo MapReduce，使之产生日志：12[root@master hadoop-2.6.5]# bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.5.jar wordcount2 /test1/input /test1/output2# 访问主节点的19888端口，运行job后就可以在web页面查看各个Map和Reduce的日志了。]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django-debug-toolbar]]></title>
    <url>%2F2019%2F07%2F19%2FDjango-debug-toolbar%2F</url>
    <content type="text"><![CDATA[django开发中的调试工具组件Django-Debug-Toolbar 介绍django-debug-toolbar 是一组可配置的面板，可显示有关当前请求/响应的各种调试信息，并在单击时显示有关面板内容的更多详细信息。 在用django开发时，最喜欢的就是ORM功能，对于不熟悉sql语句的朋友是一大福利！但是，问题也在于此，在遍历的同时也会带来一系列问题。如：一不小心，语句写的有问题就会造成全表数据加载。 安装1234# 文档地址：https://django-debug-toolbar.readthedocs.io/en/latest/installation.html # 使用pip安装pip3 install django-debug-toolbar 配置 添加debug_toolbar到INSTALL_APPS中 1234567# 先决条件，确保&apos;django.contrib.staticfiles&apos;被正确设置，&apos;debug_toolbar&apos;要在&apos;django.contrib.staticfiles&apos;下面。INSTALLED_APPS = [ # ... &apos;django.contrib.staticfiles&apos;, # ... &apos;debug_toolbar&apos;,] 设置URL 1234567891011121314# 将调试工具栏的URL添加到项目的URLconf中，在主urls.py里from django.urls import path,includefrom apps.news import viewsfrom django.conf.urls.static import staticfrom django.conf import settingsurlpatterns = [ path(&apos;&apos;,views.index,name=&apos;index&apos;), # ...]if settings.DEBUG: import debug_toolbar urlpatterns.append(path(&quot;__debug__/&quot;,include(debug_toolbar.urls))) 启用中间件 1234567# 调试工具栏主要在中间件中实现，在设置模块中启用它。MIDDLEWARE = [ # ... &apos;debug_toolbar.middleware.DebugToolbarMiddleware&apos;, # ...]# 顺序MIDDLEWARE很重要，您应该尽早在列表中包含Debug Toolbar中间件。但是，它必须在编码响应内容的任何其他中间件之后，例如 GZipMiddleware。如果没用到GZip那就放到首位。 配置内部IP 123# 仅当你的IP地址在INTERNAL_IPS设置中列出时，才会显示调试工具栏 。这意味着，对于当地的发展，你必须添加&apos;127.0.0.1&apos;到INTERNAL_IPS; 如果您的设置模块中尚不存在，则需要创建此设置：INTERNAL_IPS = [&apos;127.0.0.1&apos;] 自定义配置调试工具栏提供了两个设置，您可以在项目的设置模块中添加这些设置以自定义其行为。 DEBUG_TOOLBAR_PANELS1234567891011121314151617181920212223242526272829# 此设置指定要包含在工具栏中的每个面板的完整Python路径。它就像Django的MIDDLEWARE设置一样。根据需求开启对应功能。DEBUG_TOOLBAR_PANELS = [ # 代表是哪个django版本 &apos;debug_toolbar.panels.versions.VersionsPanel&apos;, # 用来计时的，判断加载当前页面总共花的时间 &apos;debug_toolbar.panels.timer.TimerPanel&apos;, # 读取django中的配置信息 &apos;debug_toolbar.panels.settings.SettingsPanel&apos;, # 看到当前请求头和响应头信息 &apos;debug_toolbar.panels.headers.HeadersPanel&apos;, # 当前请求的想信息（视图函数，Cookie信息，Session信息等） &apos;debug_toolbar.panels.request.RequestPanel&apos;, # 查看SQL语句 &apos;debug_toolbar.panels.sql.SQLPanel&apos;, # 静态文件 &apos;debug_toolbar.panels.staticfiles.StaticFilesPanel&apos;, # 模板文件 &apos;debug_toolbar.panels.templates.TemplatesPanel&apos;, # 缓存 &apos;debug_toolbar.panels.cache.CachePanel&apos;, # 信号 &apos;debug_toolbar.panels.signals.SignalsPanel&apos;, # 日志 &apos;debug_toolbar.panels.logging.LoggingPanel&apos;, # 重定向 &apos;debug_toolbar.panels.redirects.RedirectsPanel&apos;, # 提供了一个profiling panel，它包含了line_profiler的输出 &apos;debug_toolbar.panels.profiling.ProfilingPanel&apos;,] DEBUG_TOOLBAR_CONFIG1此字典包含所有其他配置选项。一些适用于工具栏本身，另一些适用于某些面板。 配置JQuery的URL12345678910# django-debug-toolbar 默认使用的是Google的地址，默认配置如下：JQUERY_URL = &apos;//ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js&apos;# 如果无法访问国外网站可在setting.py中配置一下DEBUG_TOOLBAR_CONFIG = &#123; &quot;JQUERY_URL&quot;: &apos;//cdn.bootcss.com/jquery/2.2.4/jquery.min.js&apos;,&#125;或者你如果在Django项目中使用了jquery的话就可以直接将这一项置为空，那么django-debug-toolbar 就会使用你项目中用到的jquery:DEBUG_TOOLBAR_CONFIG = &#123; &quot;JQUERY_URL&quot;: &apos;&apos;,&#125; 使用测试访问页面的时候在右侧有各项配置面板，点击即可查看各种调试信息。]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>toolbar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派相关配置]]></title>
    <url>%2F2019%2F07%2F19%2F%E6%A0%91%E8%8E%93%E6%B4%BE%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[下载镜像12345# 建议下载带桌面服务的https://www.raspberrypi.org/downloads/raspbianWin32 DiskImager，这是一个把镜像写入SD卡的工具：https://sourceforge.net/projects/win32diskimager/# 解压出img镜像文件，点击Write，写入系统。 格式化为F32 WIFI网络设置12345678910111213# 树莓派3B，树莓派官方Raspbian系统久加入了允许在开机前对 WiFi 网络进行配置的机制。# 原文链接：http://shumeipai.nxez.com/2017/09/13/raspberry-pi-network-configuration-before-boot.html#more-3463# 将刷好 Raspbian 系统的 SD 卡用电脑读取。在 boot 分区，也就是树莓派的 /boot 目录下新建 wpa_supplicant.conf 文件，按照下面的参考格式填入内容并保存 wpa_supplicant.conf 文件。country=CNctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdevupdate_config=1#如果你的 WiFi 使用WPA/WPA2加密network=&#123;ssid=&quot;你的无线网络名称（ssid）&quot;key_mgmt=WPA-PSKpsk=&quot;你的wifi密码&quot;&#125; 开启SSH服务1234同样在 boot 分区新建一个文件，空白的即可，文件命名为 ssh。注意要小写且不要有任何扩展名。树莓派在启动之后会在检测到这个文件之后自动启用 ssh 服务。随后即可通过登录路由器找到树莓派的 IP 地址，通过 ssh 连接到树莓派了。树莓派默认账户：pi；默认密码：raspberry使用pi账户进行登陆命令行，执行命令：【sudo passwd root】设置root用户密码，然后在执行【sudo passwd --unlock root】开启root账户，在使用【su root】测试是否生效！重新锁定root账户可执行命令：sudo passwd --lock root 树莓派更新vim1234567# 系统自带的vi编辑器很坑，需要卸载之前的vi，然后重新安装sudo apt-get remove vim-common；sudo apt-get install vim# 更改vi的配置（个人喜好）# 编辑/etc/vim/vimrc文件，在末尾添加以下内容set nu #显示行号syntax on #语法高亮set tabstop=4#tab 退四格 修改默认源12345# 备份/etc/apt/sources.list 文件，编辑/etc/apt/sources.list，删除之前内容，添加如下源(清华大学源)deb http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ jessie main non-free contribdeb-src http://mirrors.tuna.tsinghua.edu.cn/raspbian/raspbian/ jessie main non-free contrib# 保存退出sudo apt-get update &amp;&amp; apt-get upgrade -y 开启VNC123raspi-config选择5 Interfacing Options -&gt; P3 VNC调整分辨率，选择7 Advanced Options -&gt; A5 Resolution 安装teamviewer12345678910111213141516171819202122232425262728a、下载wget http://download.teamviewer.com/download/linux/version_11x/teamviewer-host_armhf.debsudo dpkg -i teamviewer-host_armhf.debsudo apt-get -f installb、安装GDebi，解决依赖问题sudo apt-get install gdebic、安装Teamviewersudo gdebi teamviewer-host_armhf.debd、命令行终端环境#查看帮助信息teamviewer help#查看本机IDteamviewer info#设置本机密码sudo teamviewer passwd [你的密码]#启动TeamViewer服务sudo teamviewer --daemon start#开启TeamViewer服务随机启动sudo teamviewer --daemon enable#重启即可连接sudo reboote、常用管理命令teamviewer --daemon start 启动TeamViewer服务teamviewer --daemon stop 停止TeamViewer服务teamviewer --daemon restart 重启TeamViewerteamviewer --daemon disable 关闭TeamViewer服务随机启动teamviewer --daemon enable 开启TeamViewer服务随机启动/usr/bin/teamviewer &amp; 打开teamviewer控制面板]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>树莓派</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker上安装mongodb]]></title>
    <url>%2F2019%2F07%2F19%2FDocker%E4%B8%8A%E5%AE%89%E8%A3%85mongodb%2F</url>
    <content type="text"><![CDATA[查看下载镜像12345# 查看镜像docker search mongo# 拉取镜像docker pull mongo# 如果要拉取指定版本，可在docker hub上查看具体所有的mongo版本，然后使用 mongo:x.x 拉取指定版本。 运行启动容器1234567docker run --name mongodb -p 27072:27017 -v /data/mongodb/db:/data/db -v /data/mongodb/configdb:/data/configdb -d mongo --auth# --name ：指定容器名# -p ：指定容器暴露端口，宿主机端口:容器内端口# -v ：指定容器存储卷，宿主机目录:容器内目录# -d ：设置容器为后台运行，后面的mongo为镜像名# --auth ：开启密码授权访问docker ps # 查看刚创建的容器 创建管用户 以admin用户身份进入mongo，创建管理员用户 1234567891011121314151617181920212223242526272829303132docker exec -it mongodb bash# -it : 已交互式的方式# 使用mongo命令，进入mongouse admin;db.createUser(&#123; user: &apos;root&apos;, pwd: &apos;mongo&apos;, roles: [ &#123; role: &quot;root&quot;, db: &quot;admin&quot;&#125;]&#125;);db.auth(&apos;root&apos;,&apos;mongo&apos;) # 返回1成功# 退出，再进入docker exec -it mongodb mongo admindb.auth(&apos;root&apos;,&apos;mongo&apos;)# 创建普通用户db.createUser(&#123; user: &apos;root&apos;, pwd: &apos;mongo&apos;, roles: [ &#123; role: &quot;readWriteAnyDatabase&quot;, db: &quot;admin&quot;&#125;]&#125;);# # role后面的参数参考,可根据时间情况选择：Read：允许用户读取指定数据库readWrite：允许用户读写指定数据库dbAdmin：允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profileuserAdmin：允许用户向system.users集合写入，可以找指定数据库里创建、删除和管理用户clusterAdmin：只在admin数据库中可用，赋予用户所有分片和复制集相关函数的管理权限。readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限dbAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限。root：只在admin数据库中可用。超级账号，超级权限# 验证db.auth(&apos;root&apos;,&apos;mongo&apos;) 客户端管理工具12# 下载Robo 3Thttps://robomongo.org/download 创建用户 python调用mongo存储数据123456789101112131415# 先安装pymongo包import pymongo# 建立连接client = pymongo.MongoClient(&apos;mongodb://liyk:***@43.x.x.x:27072/&apos;)# 没密码认证可如下连接# client = pymongo.MongoClient(&apos;43.x.x.x&apos;,27072)# 新建名为weather的数据库book_weather = client[&apos;weather&apos;]# 在weather库中新建名为sheet_weather_1的表sheet_weather = book_weather[&apos;sheet_weather_1&apos;]dict_data = strhtml2.json()# 向数据库表中插入数据sheet_weather.insert_one(dict_data)]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>mongo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Oracle DG]]></title>
    <url>%2F2019%2F07%2F19%2FOracle-DG%2F</url>
    <content type="text"><![CDATA[Data Guard DataGuard是甲骨文推出的一种高可用性数据库方案，在Oracle 8i之前被称为Standby Database。从Oracle 9i开始，正式更名为Data Guard。它是在主节点与备用节点间通过日志同步来保证数据的同步，可以实现数据库快速切换与灾难性恢复。Data Guard只是在软件上对数据库进行设置，并不需要额外购买任何组件。用户能够在对主数据库影响很小的情况下，实现主备数据库的同步。而主备机之间的数据差异只限于在线日志部分，因此被不少企业用作数据容灾解决方案。 写在前面1234# 开库顺序先启备库，再启主库（启动监听，打开告警日志）# 关库顺序先关主库再关备库 配置准备 查看数据库版本123# 主库ip：192.168.100.2；备库ip：192.168.100.3# 查看数据库版本，必须是企业版否则不支持oracle data guardSQL&gt; select * from v$version; 备库只安装软件 确保备库安装路径、实例名与主库完全一致，避免同步出错 主库配置 在/app下创建interlib文件夹(自定义文件夹名),在创建文件夹log 12# 日志文件路径：&apos;logUrl=D:\app\interlib\log&apos;# 控制文件路径：&apos;standbyUrl=D:\app\interlib&apos; 开启归档模式12345678910111213# 在主库上启动数据库到mount模式，开启归档模式与force loggingsqlplus / as sysdbaSQL&gt;shutdown immediate; SQL&gt;startup mount; #修改为归档模式SQL&gt;alter database archivelog; SQL&gt;alter database open; #设置强制归档模式SQL&gt; alter database force logging;#查看命令：select log_mode,force_logging from v$database;#查看是否归档命令：Archive log list ; 为备库创建日志文件 1234# logUrl=D:\app\interlib\log 根据实际的“日志文件路径”改变SQL&gt; alter database add standby logfile group 4 (&apos;D:/app/interlib/log/STAN04.LOG&apos;) size 50m;SQL&gt; alter database add standby logfile group 5 (&apos;D:/app/interlib/log/STAN05.LOG&apos;) size 50m;SQL&gt; alter database add standby logfile group 6 (&apos;D:/app/interlib/log/STAN06.LOG&apos;) size 50m; 创建standby控制文件 1SQL&gt; alter database create standby controlfile as &apos;D:\app\interlib\standby.ctl&apos;; 导出当前数据库参数并修改 123456789101112131415161718192021222324252627282930313233343536373839404142SQL&gt; create pfile=&apos;D:/app/interlib/initora.ora&apos; from spfile;# 修改相关路径，以及增加没有的参数orcl.__db_cache_size=654311424orcl.__java_pool_size=16777216orcl.__large_pool_size=16777216orcl.__oracle_base=&apos;D:\app\Administrator&apos;#ORACLE_BASE set from environmentorcl.__pga_aggregate_target=704643072orcl.__sga_target=1023410176orcl.__shared_io_pool_size=0orcl.__shared_pool_size=318767104orcl.__streams_pool_size=0*.audit_file_dest=&apos;D:\app\Administrator\admin\orcl\adump&apos;*.audit_trail=&apos;db&apos;*.compatible=&apos;11.2.0.0.0&apos;*.control_files=&apos;D:\app\Administrator\oradata\orcl\control01.ctl&apos;,&apos;D:\app\Administrator\flash_recovery_area\orcl\control02.ctl&apos;*.db_block_size=8192*.db_domain=&apos;&apos;*.db_name=&apos;orcl&apos;*.db_recovery_file_dest=&apos;D:\app\Administrator\flash_recovery_area&apos;*.db_recovery_file_dest_size=4102029312*.diagnostic_dest=&apos;D:\app\Administrator&apos;*.dispatchers=&apos;(PROTOCOL=TCP) (SERVICE=orclXDB)&apos;*.local_listener=&apos;LISTENER_ORCL&apos;*.memory_target=1717567488*.open_cursors=300*.processes=150*.remote_login_passwordfile=&apos;EXCLUSIVE&apos;*.undo_tablespace=&apos;UNDOTBS1&apos;# 如下是增加的参数*.db_unique_name=&apos;primary&apos;*.archive_lag_target=1800*.fal_client=&apos;standby&apos;*.fal_server=&apos;primary&apos;*.log_archive_config=&apos;DG_CONFIG=(primary,standby)&apos;*.log_archive_dest_1=&apos;LOCATION=D:\app\interlib\log\ VALID_FOR=(all_logfiles,all_roles) db_unique_name=primary&apos;*.log_archive_dest_2=&apos;service=standby arch async valid_for=(online_logfiles,primary_role) db_unique_name=standby&apos;*.log_archive_dest_state_1=&apos;enable&apos;*.log_archive_dest_state_2=&apos;enable&apos;*.log_archive_format=&apos;%t_%s_%r.dbf&apos;*.DB_FILE_NAME_CONVERT=&apos;D:\app\Administrator\oradata\orcl\&apos;,&apos;D:\app\Administrator\oradata\orcl\&apos;*.LOG_FILE_NAME_CONVERT=&apos;D:\app\interlib\log&apos;,&apos;D:\app\interlib\log&apos;*.standby_file_management=&apos;auto&apos; 重新加载配置启动服务 12345678910#停止服务SQL&gt; shutdown immediate;#使用新参数文件启动数据库SQL&gt; startup pfile=&apos;D:\app\interlib\initora.ora&apos; nomount;#创建新的 spfile 文件SQL&gt; create spfile from pfile=&apos;D:\app\interlib\initora.ora&apos;;#停止服务SQL&gt; shutdown immediate;#启动服务SQL&gt; startup; 创建密码文件 123456# 如果有此步，存在密码文件可不操作# 在DOS窗口执行，不需要登录sqlplus，路径不能加引号，否则会报opw-00001错误 orapwd file=passwordUrl\PWDorcl.ora password=123 entries=10# 密码文件存放路径：密码文件存放路径：passwordUrl=D:\app\Administrator\product\11.2.0\dbhome_1\database\PWDorcl.ora 配置监听和访问服务 1234567891011121314151617181920212223242526272829# 修改 listener.ora# listener.ora Network Configuration File: D:\app\Administrator\product\11.2.0\dbhome_1\network\admin\listener.ora# Generated by Oracle configuration tools.SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = CLRExtProc) (ORACLE_HOME = D:\app\Administrator\product\11.2.0\dbhome_1) (PROGRAM = extproc) (ENVS = &quot;EXTPROC_DLLS=ONLY:D:\app\Administrator\product\11.2.0\dbhome_1\bin\oraclr11.dll&quot;) ) # 添加SID_DESC (SID_DESC = (GLOBAL_DBNAME = orcl) (ORACLE_HOME = D:\app\Administrator\product\11.2.0\dbhome_1) (SID_NAME = orcl) ) )LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.100.2)(PORT = 1521)) ) )ADR_BASE_LISTENER = D:\app\Administrator 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 修改tnsname.ora文件# tnsnames.ora Network Configuration File: D:\app\Administrator\product\11.2.0\dbhome_1\network\admin\tnsnames.ora# Generated by Oracle configuration tools.LISTENER_ORCL = (ADDRESS = (PROTOCOL = TCP)(HOST = 92.168.100.2)(PORT = 1521))ORACLR_CONNECTION_DATA = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) ) (CONNECT_DATA = (SID = CLRExtProc) (PRESENTATION = RO) ) )ORCL = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 1922.168.100.2)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = orcl) ) )# 增加主库配置PRIMARY = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP) (HOST = 192.168.100.2) (PORT = 1521)) ) (CONNECT_DATA = (SERVICE_NAME = orcl) )) # 增加从库配置STANDBY= (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP) (HOST = 192.168.100.3) (PORT = 1521)) ) (CONNECT_DATA = (SERVICE_NAME = orcl) )) 从库配置 拷贝数据到备库 主库和备库创建 D:\app\interlib\tmp 文件夹，并把interlib其余目录也拷贝过去 将主库oracle目录下的oradata文件夹下内容复制到从库相同目录 将D:\app\Administrator 目录下的admin,cfgtollogs,diag,flash_recover_area 目录以及密码文件(‘D:\app\Administrator\product\11.2.0\dbhome_1\database\PWDorcl.ora’)拷贝到备用库的相同路径。可直接覆盖 将主库的listener.ora和tnsname.ora拷贝到备库相同路径，并修改linstener.ora的ip为备库ip (‘D:\app\Administrator\product\11.2.0\dbhome_1\NETWORK\ADMIN’)1234567LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.100.3)(PORT = 1521)) )) 备库新建实例 1234# 备库新建实例，如果备库也安装了数据库，实例也是orcl这步可跳过# 在备库上注册oracle实例到服务中，cmd下执行oradim -new -sid orcllsnrctl start 修改备库参数并创建实例12345678910111213141516# 将从主库拷贝的 D:\app\interlib\initora.ora修改#下面是要修改的地方*.db_unique_name=&apos;standby&apos;*.archive_lag_target=1800*.fal_client=&apos;primary&apos;*.fal_server=&apos;standby&apos;*.log_archive_config=&apos;DG_CONFIG=(primary,standby)&apos;*.log_archive_dest_1=&apos;LOCATION=D:\app\interlib\log\ VALID_FOR=(all_logfiles,all_roles) db_unique_name=standby&apos;*.log_archive_dest_2=&apos;service=primary arch async valid_for=(online_logfiles,primary_role) db_unique_name=primary&apos;*.log_archive_dest_state_1=&apos;enable&apos;*.log_archive_dest_state_2=&apos;enable&apos;*.log_archive_format=&apos;%t_%s_%r.dbf&apos;*.DB_FILE_NAME_CONVERT=&apos;D:\app\Administrator\oradata\orcl\&apos;,&apos;D:\app\Administrator\oradata\orcl\&apos;*.LOG_FILE_NAME_CONVERT=&apos;D:\app\interlib\log\&apos;,&apos;D:\app\interlib\log\&apos;*.standby_file_management=&apos;auto&apos; 12345# 使用新参数文件建立从库实例SQL&gt; startup nomount pfile=&apos;D:\app\interlib\initora.ora&apos;;SQL&gt; create spfile from pfile=&apos;D:\app\interlib\initora.ora&apos;;SQL&gt; shutdown immediate; （此步骤可能会报错 01507,暂时忽略）SQL&gt; startup nomount; 主库执行相关语句 建立主库备份12345# 复制主库，使用RMAN建立备份，cmd下执行rman target /RMAN&gt; backup full database format=&apos;D:\app\interlib\tmp\FOR_STANDBY_%u%p%s,RMN&apos; include current controlfile for standby;# 将当前archivelog归档，执行sql语句RMAN&gt; sql &apos;alter system archive log current&apos;; 复制数据库 12345# 复制数据库；将主库D:\app\interlib\tmp\下产生的的备份集拷贝到备库的相同路径下# 拷贝完成后在主库刚才的RMAN中执行RMAN&gt; connect auxiliary sys/123.com@standby # 123.com为备库sys的密码, 可能会提示实例未装载# 如果提示无法连接，请检查防火墙等是否有限制RMAN&gt; duplicate target database for standby nofilenamecheck; 备库启动standby1234# 在备库执行sqlplus / as sysdbaalter database mount standby database; # 可能会报错 01100不管alter database recover managed standby database disconnect from session; 检查测试 状态查看测试12# 主库从库分别执行如果 APPLIED 列的值为 yes,表示重做应用成功SELECT SEQUENCE#,APPLIED FROM V$ARCHIVED_LOG ORDER BY SEQUENCE#; 1234# 或者查看切换归档，归档日志记录会+1select max(sequence#) from v$archived_log;alter system switch logfile;select max(sequence#) from v$archived_log; 日志查看测试 1# 主库上执行alter system switch logfile;，通过select name from v$archived_log; 可以看到主库和备库都增加了一个log文件(.DBF) 查看主备库状态 12# 执行sql语句select open_mode,protection_mode,database_role,switchover_status from v$database; DG切换123456789101112# 主库执行# 先将主库切换成备库，然后将原主库启动到物理库的状态alter database commit to switchover to physical standby with session shutdown;# 关闭主库shutdown immediate;# 开数据库nomountstartup nomount;# 更改主库为备库alter database mount standby database;alter database recover managed standby database disconnect from session;# 如果配置了 standby redo log 并需要启用实时同步则执行以下代码alter database recover managed standby database using current logfile disconnect from session; 1234567# 备库执行,switchover到primary# 更改备库为主库alter database commit to switchover to primary with session shutdown;# 如果备库还有未应用的日志则执行alter database recover managed standby database disconnect from session;shutdown immediate;startup DG切换后再恢复最初 即原主库切换为备库，再从备库切换为主库 123456# 开库顺序先启备库，再启主库（启动监听，打开告警日志）# 关库顺序先关主库再关备库lsnrctl stoplsnrctl start 主库操作 1234# 登录原主库rman target /RMAN&gt; connect auxiliary sys/123.com@standbyRMAN&gt; duplicate target database for standby nofilenamecheck; 备库stnadby 1234# 在备库执行sqlplus / as sysdbaalter database mount standby database; # 可能会报错 01100不管alter database recover managed standby database disconnect from session; 状态监测 1234# 或者查看切换归档，归档日志记录会+1select max(sequence#) from v$archived_log;alter system switch logfile;select max(sequence#) from v$archived_log;]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>oracle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Memcache基础使用]]></title>
    <url>%2F2019%2F07%2F05%2FMemcache%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[连接语法12telnet HOST PORT telnet 127.0.0.1 11211 memcached set命令 Memcached set 命令用于将 value(数据值) 存储在指定的 key(键) 中。如果set的key已经存在，该命令可以更新该key所对应的原来的数据，也就是实现更新的作用。 参数说明如下： 123456key：键值 key-value 结构中的 key，用于查找缓存值。flags：可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息 。exptime：在缓存中保存键值对的时间长度（以秒为单位，0 表示永远）bytes：在缓存中存储的字节数noreply（可选）： 该参数告知服务器不需要返回数据value：存储的值（始终位于第二行）（可直接理解为key-value结构中的value） 实例（以下实例中我们设置）： 12345key → runoobflag → 0exptime → 900 (以秒为单位)bytes → 9 (数据存储的字节数)value → memcached 输出信息说明： STORED：保存成功后输出。 ERROR：在保存失败后输出。 memcached add命令 语法： 123add 命令的基本语法格式如下：add key flags exptime bytes [noreply]value 参数说明如下： 123456key：键值 key-value 结构中的 key，用于查找缓存值。flags：可以包括键值对的整型参数，客户机使用它存储关于键值对的额外信息 。exptime：在缓存中保存键值对的时间长度（以秒为单位，0 表示永远）bytes：在缓存中存储的字节数noreply（可选）： 该参数告知服务器不需要返回数据value：存储的值（始终位于第二行）（可直接理解为key-value结构中的value） 实例: 123456以下实例中我们设置：key → new_keyflag → 0exptime → 900 (以秒为单位)bytes → 10 (数据存储的字节数)value → data_value 输出:如果数据添加成功，则输出：STORED输出信息说明：STORED：保存成功后输出。NOT_STORED:在保持失败后输出。]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>Memcache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Memcache安装]]></title>
    <url>%2F2019%2F07%2F05%2FMemcached%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[简介Memcached是一个自由开源的，高性能，分布式内存对象缓存系统。Memcached是以LiveJournal旗下Danga Interactive公司的Brad Fitzpatric为首开发的一款软件。现在已成为mixi、hatena、Facebook、Vox、LiveJournal等众多服务中提高Web应用扩展性的重要因素。Memcached是一种基于内存的key-value存储，用来存储小块的任意数据（字符串、对象）。这些数据可以是数据库调用、API调用或者是页面渲染的结果。本质上，它是一个简洁的key-value存储系统。一般的使用目的是，通过缓存数据库查询结果，减少数据库访问次数，以提高动态Web应用的速度、提高可扩展性。 特征memcached作为高速运行的分布式缓存服务器，具有以下的特点。 协议简单 基于libevent的事件处理 内置内存存储方式 memcached不互相通信的分布式 支持多语言许多语言都实现了连接memcached的客户端，其中以Perl、PHP为主。仅仅memcached网站上列出的有：Perl、PHP、Python、Ruby、C#、C/C++、Lua等等 安装(linux)123456789101.安装libevent、gcc库yum install -y libevent libevent-deve gcc-c++2.下载安装包(在官网下载最新稳定版)wget http://memcached.org/files/memcached-1.5.7.tar.gz3.解压安装tar -zxvf memcached-1.x.x.tar.gzcd memcached-1.x.x./configure &amp;&amp; make &amp;&amp; make test &amp;&amp; make install4.查看命令帮助/usr/local/bin/memcached -h 启动选项123456789/usr/local/bin/memcached -d -m 64M -u root -l 127.0.0.1 -p 11211 -c 256 -P /tmp/memcache.pid/usr/local/memcache/bin/memcached -d -l 127.0.0.1 -p 11211 -u root -m 64 -c 1024 -P /var/run/memcached.pid-d 是启动一个守护进程；-m 是分配给Memcache使用的内存数量，单位是MB；-u 是运行Memcache的用户；-l 是监听的服务器IP地址，可以有多个地址；-p 是设置Memcache监听的端口，，最好是1024以上的端口；-c 是最大运行的并发连接数，默认是1024；-P 是设置保存Memcache的pid文件。 安装(windows)memcached &lt;1.4.5 版本安装123456789101112131415http://static.runoob.com/download/memcached-win64-1.4.4-14.zip1、解压下载的安装包到指定目录。2、在 1.4.5 版本以前 memcached 可以作为一个服务安装，使用管理员权限运行以下命令：c:\memcached\memcached.exe -d install注意：你需要使用真实的路径替代 c:\memcached\memcached.exe。3、然后我们可以使用以下命令来启动和关闭 memcached 服务：c:\memcached\memcached.exe -d startc:\memcached\memcached.exe -d stop4、如果要修改 memcached 的配置项, 可以在命令行中执行 regedit.exe 命令打开注册表并找到 &quot;HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\memcached&quot; 来进行修改。如果要提供 memcached 使用的缓存配置 可以修改 ImagePath 为:&quot;c:\memcached\memcached.exe&quot; -d runservice -m 512-m 512 意思是设置 memcached 最大的缓存配置为512M。此外我们还可以通过使用 &quot;c:\memcached\memcached.exe -h&quot; 命令查看更多的参数配置。5、如果我们需要卸载 memcached ，可以使用以下命令：c:\memcached\memcached.exe -d uninstall memcached &gt;= 1.4.5 版本安装1234567891、解压下载的安装包到指定目录。2、在 memcached1.4.5 版本之后，memcached 不能作为服务来运行，需要使用任务计划中来开启一个普通的进程，在 window 启动时设置 memcached自动执行。我们使用管理员身份执行以下命令将 memcached 添加来任务计划表中：schtasks /create /sc onstart /tn memcached /tr &quot;&apos;c:\memcached\memcached.exe&apos; -m 512&quot;注意：你需要使用真实的路径替代 c:\memcached\memcached.exe。注意：-m 512 意思是设置 memcached 最大的缓存配置为512M。注意：我们可以通过使用 &quot;c:\memcached\memcached.exe -h&quot; 命令查看更多的参数配置。3、如果需要删除 memcached 的任务计划可以执行以下命令：schtasks /delete /tn memcached]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>Memcache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLserver维护计划]]></title>
    <url>%2F2019%2F07%2F05%2FSQLserver%E7%BB%B4%E6%8A%A4%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[备份新建维护计划管理-&gt; 维护计划 -&gt; 新建维护计划 a.新建维护计划，设置名称b.工具箱将“备份数据库”任务拖动到设计器界面 编辑备份数据库任务右键任务，点击编辑 可自行按需设置，选择备份类型、备份数据库、选择备份到的目录、勾选验证备份完整性等。 设置作业任务属性 设置计划类型、频率等 定期清理历史备份 前几个过程和备份相同，从工具箱里拖动“清除维护”任务,编辑 这里需要注意2点 a.搜索文件夹这里，不支持递归查找，如果有多个目录需要创建多个任务，单独制定到目录b.文件扩展名为“bak”,不要写为“.bak”,这样是无法识别到的 最后设置计划类型、频率等]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>sqlserver</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx版本平滑升级-编译安装]]></title>
    <url>%2F2019%2F07%2F05%2Fnginx%E7%89%88%E6%9C%AC%E5%B9%B3%E6%BB%91%E5%8D%87%E7%BA%A7-%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[一、nginx编译安装 源码下载地址：http://nginx.org/en/download.html 安装依赖环境 1yum install gcc gcc-c++ automake pcre pcre-devel zlip zlib-devel openssl openssl-devel -y 下载源码包 1wget http://nginx.org/download/nginx-1.14.0.tar.gz 解压并编译 123tar -zxvf xxxx./configure --prefix=usr/local/nginxmake &amp;&amp; make install 软链接到/usr/bin下 1ln -s /usr/local/nginx/sbin/nginx /usr/bin/nginx 查看nginx版本 12nginx -v 查看nginx版本nginx -V 大写V，查看nginx版本及编译路径等设置 二、升级nginx1.下载需要升级的版本2.解压、编译但不安装 解压要升级的nginx，进入目录，编译和老版本一样的配置 1./configure --prefix=usr/local/nginx 编译生成objs目录，进入该目录替换nginx 1make 升级nginx不需要make install备份之前的nginx执行文件 12cd /usr/local/nginx/sbin mv nginx nginx.old 3.升级 把新编译的nginx执行脚本拷贝到对应的目录 12cp objs/nginx /usr/local/nginx/sbin/ make upgrade 4.查看版本 1nginx -v]]></content>
      <categories>
        <category>WEB</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图片上传到七牛云及图片上传进度条]]></title>
    <url>%2F2019%2F07%2F02%2F%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0%E5%88%B0%E4%B8%83%E7%89%9B%E4%BA%91%E5%8F%8A%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0%E8%BF%9B%E5%BA%A6%E6%9D%A1%2F</url>
    <content type="text"><![CDATA[七牛云存储是一个集图片、视频对象存储为一体的网站。并且他上面集成了cdn加速服务，图片处理（加水印，图片裁剪）等功能，对于一些想要快速开发产品，不想花大量时间来构建自己资源服务器的中小型公司而言，无疑是最好的选择。更主要是有免费额度。 申请七牛云账号 申请链接：https://portal.qiniu.com ,申请步骤不做过多阐述。 查看密钥：个人中心-&gt; 密钥管理 （AK、SK） 创建空间：进入对象存储-&gt; 新建存储空间 （自定义空间名称、选择存储区域、设置为公开空间） 绑定域名：七牛默认提供的域名只有30天试用时间，建议更换为自己的域名(需备案),设置后将此域名解析到生成的cname，后续访问即可通过此域名访问到图片。 图片上传到七牛云代码 在模板中引入最新版(2.5.2)的JavaScript SDK 123456789101112131415# html# 引入最新版的JavaScript SDK&lt;script src=&quot;https://unpkg.com/qiniu-js@2.5.2/dist/qiniu.min.js&quot;&gt;&lt;/script&gt;# 简单上传界面&lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;thumbnail-form&quot;&gt;缩略图&lt;/label&gt; &lt;div class=&quot;input-group&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;thumbnail-form&quot; name=&quot;thumbnail&quot;&gt; &lt;span class=&quot;input-group-btn&quot;&gt; &lt;label class=&quot;btn btn-default btn-file&quot;&gt; 上传图片&lt;input hidden type=&quot;file&quot; class=&quot;btn btn-default&quot; id=&quot;thumbnail-btn&quot;&gt; &lt;/label&gt; &lt;/span&gt; &lt;/div&gt;&lt;/div&gt; 然后监听一个type=file类型的按钮的change事件，一旦选择了文件，那么就会执行change事件，在change事件的处理函数中，我们就可以获取到当前选中的文件。然后通过七牛的SDK发送给服务器。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# jsfunction News() &#123; var self = this; self.progressGroup = $(&quot;#progress-group&quot;); self.progressBar = $(&quot;.progress-bar&quot;);&#125;News.prototype.listenQiniuUploadFileEvent = function () &#123; var self = this; var thumbnailBtn = $(&apos;#thumbnail-btn&apos;); thumbnailBtn.change(function (event) &#123; var file = this.files[0]; xfzajax.get(&#123; &apos;url&apos;: &apos;/cms/qntoken/&apos;, &apos;success&apos;: function (result) &#123; var token = result[&apos;uptoken&apos;]; var key = (new Date()).getTime() + &apos;.&apos; + file.name.split(&apos;.&apos;)[1]; var putExtra = &#123; fname: key, params: &#123;&#125;, mimeType: [&apos;image/png&apos;,&apos;video/x-ms-wmv&apos;,&apos;image/jpeg&apos;] &#125;; var config = &#123; useCdnDomain: true, retryCount: 6, region: qiniu.region.z2 &#125;; var observable = qiniu.upload(file, key, token, putExtra,config); observable.subscribe(&#123; &quot;next&quot;:self.updateUploadProgress, &quot;error&quot;:self.uploadErrorEvent, &quot;complete&quot;: self.complateUploadEvent &#125;); self.progressGroup.show(); &#125; &#125;); &#125;);&#125;;News.prototype.updateUploadProgress = function (response) &#123; var self = this; var total = response.total; var percent = total.percent; var percentText = percent.toFixed(0) + &apos;%&apos;; var progressBar = $(&quot;.progress-bar&quot;); progressBar.css(&#123;&quot;width&quot;:percentText&#125;); progressBar.text(percentText);&#125;;News.prototype.uploadErrorEvent = function (error) &#123; window.messageBox.showError(error.message);&#125;;News.prototype.complateUploadEvent = function (response) &#123; var self = this; var filename = response[&apos;key&apos;]; var domain = &quot;http://img.key***.cn/&quot;; var thumbnailUrl = domain + filename; var thumbnailInput = $(&quot;#thumbnail-form&quot;); thumbnailInput.val(thumbnailUrl); var progressGroup = $(&quot;#progress-group&quot;); progressGroup.hide();&#125;; 上传进度条Demo通过进度条，灵活的为当前工作流程或动作提供实时反馈。 https://v3.bootcss.com/components/#progress 效果图 代码 前端部分 12345678910111213141516171819# html&lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;thumbnail-form&quot;&gt;缩略图&lt;/label&gt; &lt;div class=&quot;input-group&quot;&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;thumbnail-form&quot; name=&quot;thumbnail&quot;&gt; &lt;span class=&quot;input-group-btn&quot;&gt; &lt;label class=&quot;btn btn-default btn-file&quot;&gt; 上传图片&lt;input hidden type=&quot;file&quot; class=&quot;btn btn-default&quot; id=&quot;thumbnail-btn&quot;&gt; &lt;/label&gt; &lt;/span&gt; &lt;/div&gt;&lt;/div&gt;&lt;div id=&quot;progress-group&quot; class=&quot;form-group&quot; style=&quot;display: none;&quot;&gt; &lt;div class=&quot;progress&quot;&gt; &lt;div class=&quot;progress-bar progress-bar-success progress-bar-striped&quot; role=&quot;progressbar&quot; aria-valuenow=&quot;40&quot; aria-valuemin=&quot;0&quot; aria-valuemax=&quot;100&quot; style=&quot;width: 0%&quot;&gt; 0% &lt;/div&gt; #内容起始设置为0%，这样初始上传时就只从0开始 &lt;/div&gt;&lt;/div&gt; 1234567891011121314# js// 上传函数、进度条显示News.prototype.handleFileUploadProgress = function (response) &#123; var total = response.total; var percent = total.percent; var percentText = percent.toFixed(0)+&apos;%&apos;; // 24.0909，89.000.... var progressGroup = News.progressGroup; // undefined/None progressGroup.show(); var progressBar = $(&quot;.progress-bar&quot;); progressBar.css(&#123;&quot;width&quot;:percentText&#125;); progressBar.text(percentText);&#125;;]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django数据库ORM模型]]></title>
    <url>%2F2019%2F07%2F02%2FDjango%E6%95%B0%E6%8D%AE%E5%BA%93ORM%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[ORM模型介绍随着项目越来越大，采用原生SQL的方式在代码中会出现大量的SQL语句，会出现很多问题： SQL语句重复利用率不高，越复杂的SQL语句条件越多，代码越长。会出现很多相近的SQL语句。 很多SQL语句是在业务逻辑中拼出来的，如果有数据库需要更改，就要去修改这些逻辑。会很容易漏掉对某些SQL语句的修改。 写SQL时容易忽略web安全问题，给未来造成安全隐患。 ORM，全称Object Relational Mapping，对象关系映射。通过ORM我们可以通过类的方式去操作数据库，而不再写原生的SQL语句。通过==把表映射成类，把行作为实例，把字段作为属性==，ORM在执行对象操作的时候最终还是会把对应的操作转换为数据库原生语句。 使用ORM优点： 易用性：使用ORM做数据库的开发可有效的减少重复SQL语句的概率，写出来的模型也更加直观、清晰。 性能损耗小：ORM转换成底层数据库操作指令确实会有一些开销，但这种性能损耗很小(不足5%)只要不是对性能有严苛要求，综合考虑开发效率、代码的阅读性，带来的好处要远远大于性能损耗，而且项目越大作用越明显。 设计灵活：可以轻松的写出复杂的查询。 可移植性：Django封装了底层的数据库实现，支持多个关系数据库引擎。包括流行的mysql、postgresql和sqlite，可以非常轻松的切换数据库。 创建ORM模型ORM模型一般都是放在app的models.py文件中，每个app都可以拥有自己的模型，并且如果这个模型想要映射到数据库中，那么这个app必须要放在settings.py的INSTALLED_APP中进行安装。 1234567from django.db import modelsclass Book(models.Model): name = models.CharField(max_length=20,null=False) author = models.CharField(max_length=20,null=False) pub_time = models.DateTimeField(default=datetime.now) price = models.FloadField(default=0)# 这个模型继承自django.db.models.Model，如果这个模型想要映射到数据库中，就必须继承自这个类。这个模型以后映射到数据库中，表名是模型名称的小写形式为book。 表中有四个字段 name：保存的是书的名称，varchar类型，最长不能超过20个字符，并且不能为空。 author：作者名字类型，varchar类型，长度不超过20个字符。 pub_time:出版时间，数据类型是datetime类型，默认是保存这本书时间。 price：书本价格，浮点类型。 在django中如果一个模型没有定义主键，那么将会自动生成一个自动增长的int类型的主键，并且这个主键的名字就叫做id。 映射模型到数据库：将ORM模型映射到数据库中，总结起来就是以下几步： 1.在settings.py中，配置好DATABASES，做好数据库相关的配置。 2.在app中的models.py中定义好模型，这个模型必须继承自django.db.models。 3.将这个app添加到setting.py的INSTALLED_APP中 4.在命令行终端，进入到项目所在的路径，然后执行命令python manage.py makemigrations来生成迁移脚本文件。 5.再执行命令python manage.py migrate来迁移脚本文件映射到数据库中。 如果要将一个普通的类变成一个可以映射到数据库中的ORM模型，那么必须要将父类设置为models.Model或者其他的子类。 123456789101112131415161718192021222324252627282930313233343536373839# settings.pyDATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;:&apos;mysite&apos;, &apos;USER&apos;:&apos;root&apos;, &apos;PASSWORD&apos;:&apos;****&apos;, &apos;HOST&apos;:&apos;43.x.x.x&apos;, &apos;PORT&apos;:&apos;3306&apos;, &#125;&#125;INSTALLED_APPS = [ &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &apos;front&apos;, &apos;book&apos;,]# models.pyfrom django.db import modelsclass Book(models.Model): # id,int类型，自增长的；不定义默认也是有的。 id = models.AutoField(primary_key=True) name = models.CharField(max_length=100,null=False) author = models.CharField(max_length=100,null=False) price = models.FloatField(null=False,default=0) def __str__(self): # &lt;Book:(name,author,price)&gt; return &quot;&lt;Book:(&#123;name&#125;,&#123;author&#125;,&#123;price&#125;)&gt;&quot;.format(name=self.name,author=self.author,price=self.price)class pulisher(models.Model): name = models.CharField(max_length=100,null=False) adderss = models.CharField(max_length=100,null=False) OMR对数据的基本操作添加数据123# 使用ORM模型创建一个对象，然后再调用这个ORM模型的save方法就可以保存了。book = Book(name=&apos;随记&apos;,author=&apos;哈哈&apos;,price=&apos;179&apos;)book.save() 查找数据123456# 所有的查找工作都是使用模型上的objects属性来完成的。1、根据主键进行查找，也可以使用objects.get方法。然后传递pk=xx的方式进行查找。book = Book.objects.get(pk=2)print(book)2、根据其他字段进行查找，objects.filter方法查找，返回一个类似列表的数据，可使用first来获取第一值。books = Book.objects.filter(name=&apos;西游记&apos;).first() 删除数据123# 首先查找到对应数据模型，然后再执行这个模型的delete，即可删除。book = Book.objects.get(pk=4)book.delete() 修改数据1234# 首先查找到对应的数据模型，然后修改这个模型上的属性的值，再执行save方法即可修改完成。book = Book.objects.get(pk=5)book.author = &apos;猪猪憨&apos;book.save()]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 外键和表关系]]></title>
    <url>%2F2019%2F07%2F02%2FDjango-%E5%A4%96%E9%94%AE%E5%92%8C%E8%A1%A8%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[外键mysql中常见2种引擎，一种是InnoDB，另外一个是MyIsam。InnoDB引擎是支持外键约束的，外键的存在使得ORM框架在处理表关系的时候异常的强大。 类定义为class Foreignkey(to,on_delete,**options) 第一个参数是引用的哪个模型 第二个参数是在使用外键引用的模型数据被删除了，这个字段如何处理。比如有CASCADE（默认的选项，级联删除）、SET_NULL（置空模式，删除的时候，外键字段被设置为空）等。 123456789101112# models.py# User模型在user这个app中calss User(models.Model): username = models.CharField(max_length=20) password = models.CahrField(max_length=200)# Article模型在article这个app中class Article(model.Molde): title = models.CharField(max_length=100) content = models.TextField() author = models.ForeignKey(&quot;user.User&quot;,on_delete=models.CASCADE) # category = models.ForeignKey(&quot;User&quot;,on_delete=models.CASCADE,null=True) # 如果外键是在其他app上，写法是：app.模型名 如果模型的外键引用的是本身自己这个模型，那么to参数可以为self，或者是这个模型的名字。在论坛开发中，定义模型就需要使用外键来引用自身。 12345class Comment(models.Model): content = models.TextField() origin_comment = models.ForeignKey(&apos;self&apos;,on_delete=models.CASCADE,null=True) # 或者 # models.ForeignKey(&apos;Comment&apos;,on_delete=models.CASCADE,null=True) 外键删除操作如果一个模型使用了外键，那么在对方那个模型被删除后，该进行什么样的操作。可以通过on_delete来指定，可以指定的类型如下： 12345678910111213# urls.pyfrom django.urls import pathfrom book import viewsurlpatterns = [ # path(&apos;&apos;,views.index), path(&apos;delete/&apos;,views.delete_view)]# views.pydef delete_view(request): category = Category.objects.get(pk=1) category.delete() return HttpResponse(&quot;delete success!&quot;) CASCADE：级联操作。如果外键对应的那条数据被删除了，那么这条数据也会被删除。 PROTECT：受保护。即只要这条数据引用了外键的那条数据，那么就不能删除外键的那条数据。 SET_NULL：设置为空。如果外键的那条数据被删除了，那么在本条数据上就将这个字段设置为空。如果设置这个选项，前提是要指定这个字段可以为空。 SET_DEFAULT：设置默认值。如果外键的那条数据被删除了，那么本条数据上就将这个字段设置为默认值。如果设置这个选项，前提是要指定这个字段一个默认值。 SET()：如果外键的那条数据被删除了。那么将会获取SET函数中的值来作为这个外键的值。SET函数可以接收一个可以调用的对象（比如函数或者方法），如果是可以调用的对象，那么会将这个对象调用后的结果作为值返回回去。 DO_NOTHING：不采取任何行为。一切全看数据库级别的约束。 表关系表之间的关系都是通过外键来进行关联的，包括三种关系：一对一、一对多(多对一)、多对多等。 一对多 应用场景：比如文章和作者之间的关系，一个文章只能由一个作者编写，但是一个作者可以写多篇文章。这种就是典型的一对多关系。 实现方式：一对多或者多对一，都是通过ForeignKey来实现的。 1234567class User(models.Model): username = models.CharField(max_length=20) password = models.CharField(max_length=100) class Article(models.Model): title = models.CahrField(max_length=100) content = models.TextField() author = models.ForeignKey(&quot;User&quot;,on_delete=models.CASCADE) 那么以后在给Article对象指定author就可以使用以下代码来完成 123456article = Article(title=&apos;abc&apos;,content=&apos;123&apos;)author = User(username=&apos;hahawa&apos;,password=&apos;123.com&apos;)# 要先保存到数据库中author.save()article.author = authorarticle.save() 123456789101112131415161718def one_to_many_view(request): # 1.一对多 # article = Article(title=&apos;钢铁是怎样炼成的&apos;,content=&apos;just do it&apos;) # category = Category.objects.first() # author = frontUser.objects.first() # article.category = category # article.author= author # article.save() # 2.获取某个分类下所有稳赚 # category = Category.objects.first() # articles = category.article_set.all() # for i in articles: # print(i) # 3.添加数据，bulk category = Category.objects.first() article = Article(title=&apos;111&apos;,content=&apos;222&apos;) article.author = frontUser.objects.first() category.article_set.add(article,bulk=False) 一对一 应用场景：比如一个用户表和一个用户信息表。如果把所有信息都存放到一张表中可能会影响查询效率，因此可以把用户的一些不常用的信息存放到另外一张表中我们叫做UserExtension。但是用户表User和用户信息表UserExtension就是典型的一对一了。 实现方式：Django为一对一提供了一个专门的Field叫做OneToOneField来实现一对一操作。 1234567class User(models.Model): username = models.CharField(max_length=20) password = models.CharField(max_length=100)class UserExtension(models.Model): birthday = models.DateTimeField(null=True) school = models.CharField(blank=True,max_length=50) user = models.OneToOneField(&quot;User&quot;, on_delete=models.CASCADE) 在UserExtension模型上增加了一个一对一的关系映射。其实底层是在UserExtension这个表上增加了一个user_id，来和user表进行关联，并且这个外键数据在表中必须是唯一的，来保证一对一。 多对多 应用场景：比如文章和标签的关系。一篇文章可以有多个标签，一个标签可以被多个文章所引用。因此标签和文章的关系是典型的多对多的关系。 实现方式：Django为这种多对多的实现提供了专门的Field。叫做ManyToManyField。 123456class Article(models.Model): title = models.CharField(max_length=100) content = models.TextField() tags = models.ManyToManyField(&quot;Tag&quot;,related_name=&quot;articles&quot;)class Tag(models.Model): name = models.CharField(max_length=50) 在数据库层面，实际上Django是为这种多对多的关系建立了一个中间表。这个中间表分别定义了两个外键，引用到article和tag两张表的主键。]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django ORM模型迁移]]></title>
    <url>%2F2019%2F07%2F02%2FDjango%E8%BF%87%E6%BB%A4%E5%99%A8%E3%80%81%E6%A8%A1%E6%9D%BF%E7%BB%A7%E6%89%BF%E3%80%81%E5%8A%A0%E8%BD%BD%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[迁移命令12python manage.py makemigrationspython manage.py migrate makemigrations：将模型生成迁移脚本。模型所在的app，必须放在settings.py中的INSTALLED_APPS中。 app_label：后面可以跟一个或者多个app，那么就只会针对这几个app生成迁移脚本。如果没有任何的app_label，那么会检查INSTALLED_APPS中所有的app下的模型，针对每一个app都生成响应的迁移脚本。 name：给这个迁移脚本指定一个名字。 empty：生成一个空的迁移脚本。如果你想写自己的迁移脚本，可以使用这个命令来实现一个空的文件，然后自己再在文件中写迁移脚本。 migrate：将新生成的迁移脚本。映射到数据库中。创建新的表或者修改表的结构。以下一些常用的选项： app_label：将某个app下的迁移脚本映射到数据库中。如果没有指定，那么会将所有在INSTALLED_APPS中的app下的模型都映射到数据库中。 app_label migrationname：将某个app下指定名字的migration文件映射到数据库中。 –fake：可以将指定的迁移脚本名字添加到数据库中。但是并不会把迁移脚本转换为SQL语句，修改数据库中的表。 –fake-initial：将第一次生成的迁移文件版本号记录在数据库中。但并不会真正的执行迁移脚本。 showmigrations：查看某个app下的迁移文件。如果后面没有app，那么将查看INSTALLED_APPS中所有的迁移文件。 sqlmigrate：查看某个迁移文件在映射到数据库中的时候，转换的SQL语句。 migrations中的迁移版本和数据库中的迁移版本对不上 1、找到哪里不一致，然后使用python manage.py –fake [版本名字]，将这个版本标记为已经映射。 2、删除指定app下migrations和数据库表django_migrations中和这个app相关的版本号，然后将模型中的字段和数据库中的字段保持一致，再使用命令python manage.py makemigrations重新生成一个初始化的迁移脚本，之后再使用命令python manage.py makemigrations –fake-initial来将这个初始化的迁移脚本标记为已经映射。以后再修改就没有问题了。]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python安装虚拟环境]]></title>
    <url>%2F2019%2F07%2F02%2Fpython%E5%AE%89%E8%A3%85%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[安装virtualenvvirtualenv是用来创建虚拟环境的软件工具，可通过pip来安装 1pip install virtualenv 创建虚拟环境12virtualenv xxx(虚拟环境的名字)#要注意，这个创建虚拟环境后会在当前路径下创建虚拟环境名的文件夹，故需要先进入指定文件夹再创建虚拟环境。 进入环境进入虚拟环境在不同的操作系统中有不同的方式，分为windows和linux： windows虚拟环境：进入到虚拟环境的scripts文件中，然后执行activate。 linux虚拟环境：source /path/to/virtualenv/bin/activate 一旦你进入到这个虚拟环境中，安装、卸载包都是在这个虚拟环境中，不会影响到外面的环境。 退出虚拟环境命令 deactivate 创建虚拟环境时指定python解释器1virtualenv -p C:\python36\python.exe [virutalenv name] virenvwrapper让管理虚拟环境变得更加简单，不用去到目录下通过virtualenv来创建虚拟环境、以及激活。 安装virtualenvwrapper12pip install virtualenvwrapper #linuxpip install virtualenvwrapper-win #windows virtualenvwrapper基本使用 创建虚拟环境 12mkvirtualenv my_env#会在当前用户下创建一个env文件夹，然后将这个虚拟环境安装到这个目录下。 切换到某个虚拟环境 1workon my_env 退出当前虚拟环境 1deactivate 删除某个虚拟环境 1rmvirtualenv my_env 列出所有虚拟环境 1lsvirtualenv 进入到虚拟环境所在的目录 1cdvirtualenv 修改mkvirtualenv的默认路径在系统环境变量里添加参数 WORKON_HOME，将这个参数的值设置为你需要的路径。 创建虚拟环境时指定python版本使用mkvirtualenv时，指定–python的参数来指定具体的python路径： 1mkvirtualenv --python==D:\Python36\python.exe haha_env]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django基础概念]]></title>
    <url>%2F2019%2F07%2F02%2FDjango%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[Django遵循MVC设计模式的框架，MVC是Model、View、Controller的三个单词的简写。分别代表模型、视图、控制器。 创建项目 通过命令行方式，首先进入到安装了Django的虚拟环境中 通过pycharm方式1234567# 创建项目1、命令行：django-admin startproject [项目名称]2、pycharm方式：文件-&gt;创建项目-&gt;选择django。然后指定项目所在的路径，以及python解释器。#运行项目python manage.py runserver可添加端口 python manage.py runserver 8088对公访问 python manage.py runserver 0.0.0.0 8088 项目结构介绍 manage.py：和项目交互都基于这个文件，python manage.py [子命令] settings.py：本项目的设置项，所有和项目相关的配置都是放在这个里面 urls.py：用来配置URL路由的，比如访问http://127.0.0.1/news/ 是访问新闻列表页，这些东西就需要在这个文件中完成。 wsgi.py：项目与WSGI协议兼容的web服务器入口，部署的时候需要用到的，一般情况下也是不需要修改的。 创建app1python manage.py startapp django_1 视图函数 视图函数的第一个参数必须是request,这个参数不能少 视图函数的返回值必须是django.http.response.HttpResponseBase的子类的对象。 URL传递参数 url映射 要去urls.py文件中寻找映射是因为在settings.py文件中配置了ROOT_URLCONF为urls.py。所有的django会去urls.py中寻找。 在urls.py中我们所有的映射都应该放在urlpatterns这个变量中。 所有的映射不是随便写的，而是使用path函数或者是re_path函数进行包装的。 url传参数 采用在url中使用变量的方式：在path的第一个参数中，使用&lt;参数名&gt;的方式传递参数，然后在视图函数中也要写一个参数。视图函数中的参数必须和url中的参数名称保持一致，不然找不到这个参数。 采用查询字符串的方式：在url中不需要单独的匹配查询字符串的部分，只需要在视图函数中使用request.GET.get(&#39;参数名称&#39;)的方式来获取。代码如下： 1234def author_detail(request): author_id = request.GET[&apos;id&apos;] text = &apos;作者id是：%s&apos; % author_id return HttpResponse(text) 因为查询字符串使用的是GET请求，所以我们通过request.GET来获取参数，并且因为GET是一个类似于字典的数据类型，所有获取值跟字典的方式都是一样的。 url命名 需要url命名的原因 因为url是经常变化的，写死可能会经常修改代码。给url取个名字以后使用url的时候就使用它的名字进行反转就可以了。 如何给一个url指定名称 在path函数中，传递一个name参数就可以指定。 1234567891011121314151617# urls.pyfrom django.urls import pathfrom . import viewsurlpatterns = [ path(&apos;&apos;,views.index,name=&apos;index&apos;), path(&apos;signin/&apos;,views.login,name=&apos;login&apos;)]# views.pyfrom django.http import HttpResponsefrom django.shortcuts import redirect,reversedef index(request): username = request.GET.get(&apos;username&apos;) if username: return HttpResponse(&apos;前台首页&apos;) else: return redirect(reverse(&apos;login&apos;)) 应用命名空间在多个app之间，有可能产生同名的url。这时为了避免反转url的时候产生混淆，可以使用应用命名空间来做区分。定义应用命名空间非常简单，只要在app的urls.py中定义一个叫做app_name的变量来指定这个应用的命名空间即可。 1234567891011121314151617181920# urls.pyfrom django.urls import pathfrom . import viewsapp_name = &apos;front&apos;urlpatterns = [ path(&apos;&apos;,views.index,name=&apos;index&apos;), path(&apos;signin/&apos;,views.login,name=&apos;login&apos;)]# views.pyfrom django.http import HttpResponsefrom django.shortcuts import redirect,reversedef index(request): username = request.GET.get(&apos;username&apos;) if username: return HttpResponse(&apos;前台首页&apos;) else: return redirect(reverse(&apos;front:login&apos;)) 应用命名空间和实例名空间 12345678# 一个app可以创建多个实例，可以使用多个url映射同一个app。在做反转的时候使用应用命名空间，那么就会发生混淆，为了避免这个问题就可以使用实例命名空间。在include函数中传递一个namespace变量即可。# urls.py from django.urls import path,includeurlpattterns = [ path(&apos;&apos;,include(&apos;front.urls&apos;)), path(&apos;cms1/&apos;,include(&apos;cms.urls&apos;,namespace=&apos;cms1&apos;)), path(&apos;cms2/&apos;,include(&apos;cms.urls&apos;,namespace=&apos;cms2&apos;))] url分层模块化多个app后主app的urls.py里的urlpatterns会写入过多路径，可通过在app里创建自身app对应的urls.py来方便路径转发。 1234567891011121314151617# 主urls.py,使用include函数包含子urls.pyfrom django.urls import path,includeurlpattterns = [ path(&apos;book/&apos;,include(&apos;book.urls&apos;)) # 以book开头的url都会转到book app下的urls.py]# book app的 urls.pyfrom django.urls import pathfrom . import viewsurlpattterns = [ path(&apos;&apos;,views.book), path(&apos;detail/&lt;book_id&gt;&apos;,views.book_detail), path(&apos;list/&apos;,views.book_list),] reverse函数补充1、如果反转url的时候，需要添加参数，那么可以传递kwargs参数到reverse函数中。2、如果想要添加查询字符串的参数，则必须手动的进行拼接。 123456789101112131415161718192021222324252627282930# views.pyfrom django.http import HttpResponsefrom django.shortcuts import reverse,redirectdef index(request): username = request.GET.get(&apos;username&apos;) if username: return HttpResponse(&quot;首页&quot;) else: # login_url = reverse(&apos;login&apos;) + &quot;?next=/&quot; # return redirect(login_url) detail_url = reverse(&apos;detail&apos;,kwargs=&#123;&apos;article_id&apos;:1,&apos;page&apos;:2&#125;) return redirect(detail_url) def login(request): return HttpResponse(&quot;登录页面&quot;)def article_detail(request,article_id): text = &apos;您的文章id是:%s&apos; % article_id return HttpResponse(text) # urls.pyfrom django.urls import pathfrom front import viewsurlpatterns = [ path(&apos;&apos;,views.index,name=&apos;index&apos;), path(&apos;login/&apos;,views.login,name=&apos;login&apos;), path(&apos;detail/&lt;article_id&gt;/&lt;page&gt;/&apos;,views.article_detail,name=&apos;detail&apos;)] 创建项目 创建app：python manage.py startapp cms 将创建的app放入统一路径下，例如放入apps文件夹下 app中编写views.py 123from django.shortcuts import renderdef login_view(request): return render(request,&apos;cms/login.html&apos;) app中编写urls.py 12345678from django.urls import pathfrom . import viewsapp_name = &apos;cms&apos;urlpatterns = [ path(&apos;login/&apos;,views.login_view,name=&apos;login&apos;)] 默认app中添加urls12345from django.urls import path,includeurlpatterns = [ path(&apos;&apos;, include(&quot;apps.news.urls&quot;)), path(&apos;cms/&apos;,include(&quot;apps.cms.urls&quot;)),]]]></content>
      <categories>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell脚本一键mvn发布war包]]></title>
    <url>%2F2019%2F07%2F02%2FShell%E8%84%9A%E6%9C%AC%E8%87%AA%E5%8A%A8mvn%E5%8F%91%E5%B8%83war%E5%8C%85%2F</url>
    <content type="text"><![CDATA[脚本初衷 客户想减少手动发布过程，减少部分工作量。但是客户不会使用jenkins，想直接脚本执行然后发布。 脚本发布步骤 登录github，拉取指定项目到本地 构建war包 停止tomcat服务 替换war包 启动tomcat服务 详细脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195#!/bin/bash# author:key.liyk# version: v1.0# func: auto build war package[ -f /etc/init.d/functions ] &amp;&amp; . /etc/init.d/functions[ $(id -u) != &quot;0&quot; ] &amp;&amp; echo &quot;You need use root to run this script&quot; &amp;&amp; exit 1clearcat &lt;&lt;EOF$(printf %.s# &#123;1..44&#125;)# _ _ ## __ _ _ __ ___| |__ _ __ ___| |_ ## / _\ | &apos;_ \ / __| &apos;_ \| &apos;_ \ / _ \ __| ## | (_| | | | | (__| | | | | | | __/ |_ ## \__,_|_| |_|\___|_| |_|_| |_|\___|\__| ## ## The script for maven deploy! #$(printf %.s+ &#123;1..44&#125;)EOFcat &lt;&lt;EOF 1: Maven deploy 2: EXIT (or ctrl+c) EOF# 定义相关目录git_dir=/data/softapps #定义git拉取存放目录tomcat_dir=/data/tomcat9 #定义tomcat目录git_url=&quot;https://github.com/liyk1024/wartest.git&quot; #定义自己github项目clone路径git_name=wartest #github项目名remove_dir=/tmp/remove-war #移除后war目录log_file=/tmp/install.log #定义日志目录mvn_path=/data/maven3/bin# 定义日志显示信息do_log() &#123; local color=$1 local level=$2 shift # shift位置参数偏移 shift local msg=$@ local prefix=&quot;&quot; if [[ $color -gt 30 ]]; then prefix=&quot;\033[1;$color;40m[$level]\033[0m&quot; else prefix=&quot;[$level]&quot; fi echo -e &quot;$prefix [`date +&apos;%Y-%m-%d %H:%M:%S&apos;`] $msg&quot;&#125;log_info() &#123; local msg=$@ do_log 0 INFO $msg&#125;log_warn() &#123; local msg=$@ do_log 33 WARN $msg&#125;log_error() &#123; local msg=$@ do_log 31 ERROR $msg&#125;log_success() &#123; local msg=$@ do_log 32 SUCCESS $msg&#125;# 检查目录check_dir() &#123;log_info check directory...for dir in $*;do [ ! -d $dir ] &amp;&amp; mkdir -p $dir &amp;&gt;&gt; $log_filedone[ $? -eq 0 ] &amp;&amp; log_success check over&#125;# 检查基础命令check_command() &#123;log_info check basic commands...for cmd in $*;do hash $cmd &amp;&gt;&gt; $log_file if [ $? -ne 0 ];then action &quot;$&#123;cmd&#125; check&quot; /bin/false log_info $&#123;cmd&#125; not find,installing... yum -y install $cmd &amp;&gt;&gt; $log_file else action &quot;$&#123;cmd&#125; check&quot; /bin/true fidone[ $? -eq 0 ] &amp;&amp; log_success check over&#125;# 检查javacheck_java() &#123;log_info check java...hash java &amp;&gt;&gt; $log_fileif [ $? -eq 0 ];then action &quot;java check&quot; /bin/trueelse action &quot;java check&quot; /bin/false log_error Pls install java! exit 1fi&#125;# 检查mavencheck_mvn() &#123;log_info check maven...hash mvn &amp;&gt;&gt; $log_fileif [ $? -ne 0 ];then action &quot;maven check&quot; /bin/trueelse action &quot;maven check&quot; /bin/false log_error Pls install maven! exit 1fi&#125;# 拉取代码git_pull() &#123;log_info check git project...find $&#123;git_dir&#125; -type d -name $&#123;git_name&#125; |xargs rm -rvf &amp;&gt;&gt; $log_filelog_info git clone...cd $&#123;git_dir&#125;git clone $git_url &amp;&gt;&gt; $log_file[ $? -eq 0 ] &amp;&amp; log_success git pull over! &#125;# 构建war包build() &#123;log_info begin build warPackage...cd $&#123;git_dir&#125;/$&#123;git_name&#125;if [ -f pom.xml ];then $&#123;mvn_path&#125;/mvn clean package -Dmaven.test.skip=true &amp;&gt;&gt; $log_file war=`find $&#123;git_dir&#125;/$&#123;git_name&#125; -name &quot;*.war&quot; |wc -l` if [ $war -eq 1 ];then log_success build war success! else log_error build war fail! exit 1 fielse log_warn Pls check,not find pom.xml! exit 1fi&#125;# 停止tomcatstop_tomcat() &#123;sh $&#123;tomcat_dir&#125;/bin/shutdown.sh &amp;&gt;&gt; $log_file[ $? -eq 0 ] &amp;&amp; log_success stop_tomcat over!&#125;# 替换war包remove_war() &#123;cd $&#123;tomcat_dir&#125;/webappsif [ -d ROOT ];then rm -rf ROOTfiwar_url=`find $&#123;git_dir&#125;/$&#123;git_name&#125; -name &quot;*.war&quot;`cp $&#123;war_url&#125; $&#123;tomcat_dir&#125;/webapps/ROOT.war&#125;# 启动tomcatstart_tomcat() &#123;sh $&#123;tomcat_dir&#125;/bin/startup.sh &amp;&gt;&gt; $log_file[ $? -eq 0 ] &amp;&amp; log_success startup_tomcat over!&#125;main() &#123;check_dir $git_dir $remove_dircheck_command git wgetcheck_javacheck_mvngit_pullbuildstop_tomcatremove_warstart_tomcat&#125;# 根据选择操作read -p &quot;Please input your choice:&quot; choiceif [ $choice = 1 ];then echo &quot;&quot; echo -e &quot;You can view detail use: \033[5;33mtail -f $&#123;log_file&#125;\033[0m&quot; log_info Start Maven deploy... mainelif [[ $choice = 2 ]];then log_info Your choice Exit! exit 0else log_warn pls choice 1|2 exit 1fi]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[腾讯云网络灾备方案]]></title>
    <url>%2F2019%2F07%2F01%2F%E8%85%BE%E8%AE%AF%E4%BA%91%E7%BD%91%E7%BB%9C%E7%81%BE%E5%A4%87%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[客户需求上海区云、北京区云、IDC互通。上海区是生产环境、北京区是灾备、IDC是办公室机房 具体要求：1、2条专线分别从IDC-上海、IDC-北京，能做到双活切换2、上海、北京互通，北京灾备保持与上海的数据一致。 实施难点 网段重叠：客户的上海、北京、IDC均是172.18.0.0/16网段 专线切换：IDC-上海、IDC-北京，任意一条专线中断可自动切换到另外一条。 需求分析1、由于网段重叠，无法使用对等连接，只能使用云联网 来解决网段重叠问题。2、客户IDC也是172.18.0.0/16网段，导致在上海、北京分别到IDC的路由冲突，无法同时存在。故只能做到主备，正常开启上海的路由，上海-IDC专线中断后切换到北京-IDC。使用python调用云联网SDK操作开启/关闭路由。3、北京灾备方面，云数据库用DTS实时同步数据、网站文件利用COS迁移工具将上海CVM数据迁移到北京COS，然后北京服务器再从COS取数据。或者直接使用rsync同步数据。北京服务器可由上海已配置环境的服务器做镜像，镜像复制到北京，再利用镜像开出服务器。 操作配置 1、云联网配置 新建云联网(目前公测阶段，需要申请此产品)，并关联对应实例 关联实例后会自动把实例所拥有的路由自动添加到云联网路由表里。 2、专线配置(云平台) 专线网关创建配置(云产品-&gt;私有网络-&gt;专线网关)新建专线网关时，关联网络类型要选择为云联网，云联网实例可现在关联也可之后关联。 专用通道创建配置(云产品-&gt;专线接入-&gt;专用通道)创建专用通道时选择专线类型，本例使用的是共享专线，需要填写专线提供方的账户ID、共享专线ID，接入网络选择云联网。一条专线(专用通道)对应一个专线网关。VLAN ID、IDC侧BGP AS号这些需向专线提供方索要，边界IP和专线提供方协商规划。这些配置完毕后等待专线提供方接受提交的申请，然后再IDC设置上配置BGP宣告IDC内网网段，如果路由方式是静态路由那就在设备上写到云上的路由。 3、专线网关上添加路由 点击需要添加路由的专线网关，进入IDC网段添加需要的IDC网段如果此专线网关未加入云联网，请在云联网下关联此专线网关，在专线网关上添加的路由会自动添加到云联网路由表里。在云联网路由表里可看出路由的详情，下一跳、是否启动该路由等。如果存在路由重叠，优先匹配长掩码(例如同网段24和25掩码,优先匹配25掩码的路由)。如果路由网段相同后添加的则自动禁用此路由。 使用云联网SDK自动切换路由 1、编写相关代码将代码放置到相关服务器上，触发脚本条件可设置为ping隧道边界ip及IDC内网ip，如果同时不通则触发脚本切换专线。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#! /usr/bin/env python# -*- coding:utf-8 -*-# Auther: liyk time:2019/1/3# File : CCN.pyfrom tencentcloud.common import credentialfrom tencentcloud.vpc.v20170312 import vpc_client,modelsimport jsondef Auth_vpc(id,key): # 认证ak cred = credential.Credential(id,key) Vpc_client = vpc_client.VpcClient(cred,&quot;ap-shanghai&quot;) return Vpc_clientdef SH_DescribeCcnRoutesRequest(Vpc_client): # 获取上海专线网关路由ID req = models.DescribeCcnRoutesRequest() req.CcnId = &apos;ccn-a187ua1z&apos; resp = Vpc_client.DescribeCcnRoutes(req) result = json.loads(resp.to_json_string()) RouteSet = result[&apos;RouteSet&apos;] SH_RouteIds = [] for i in RouteSet: if i[&apos;InstanceName&apos;] == &quot;shanghai-IDC&quot;: SH_RouteId = i[&apos;RouteId&apos;] SH_RouteIds.append(SH_RouteId) return SH_RouteIdsdef BJ_DescribeCcnRoutesRequest(Vpc_client): # 获取北京专线网关路由ID req = models.DescribeCcnRoutesRequest() req.CcnId = &apos;ccn-a187ua1z&apos; resp = Vpc_client.DescribeCcnRoutes(req) result = json.loads(resp.to_json_string()) RouteSet = result[&apos;RouteSet&apos;] BJ_RouteIds = [] for i in RouteSet: if i[&apos;InstanceName&apos;] == &quot;beijing-IDC&quot;: BJ_RouteId = i[&apos;RouteId&apos;] BJ_RouteIds.append(BJ_RouteId) return BJ_RouteIdsdef SH_EnableCcnRoutes(Vpc_client,SH_id): # 开启上海路由 req = models.EnableCcnRoutesRequest() req.CcnId = &apos;ccn-a187ua1z&apos; req.RouteIds = [&apos;%s&apos; %SH_id] print(&apos;开启上海路由 %s&apos; % SH_id) resp = Vpc_client.EnableCcnRoutes(req) # print(resp.to_json_string())def BJ_EnableCcnRoutes(Vpc_client,BJ_id): # 开启北京路由 req = models.EnableCcnRoutesRequest() req.CcnId = &apos;ccn-a187ua1z&apos; req.RouteIds = [&apos;%s&apos; %BJ_id] print(&apos;开启北京路由 %s&apos; % BJ_id) resp = Vpc_client.EnableCcnRoutes(req)def SH_DisableCcnRoutes(Vpc_client,SH_id): req = models.DisableCcnRoutesRequest() req.CcnId = &apos;ccn-a187ua1z&apos; req.RouteIds = [&apos;%s&apos; %SH_id] print(&apos;关闭上海路由 %s&apos; % SH_id) resp = Vpc_client.DisableCcnRoutes(req)def BJ_DisableCcnRoutes(Vpc_client,BJ_id): req = models.DisableCcnRoutesRequest() req.CcnId = &apos;ccn-a187ua1z&apos; req.RouteIds = [&quot;%s&quot; %BJ_id] print(&apos;关闭北京路由 %s&apos; % BJ_id) resp = Vpc_client.DisableCcnRoutes(req)if __name__ == &quot;__main__&quot;: id = &apos;AKID*******sTzK&apos; key = &apos;KUWT*******M&apos; Vpc_client = Auth_vpc(id, key) SH_RouteIds = SH_DescribeCcnRoutesRequest(Vpc_client) BJ_RouteIds = BJ_DescribeCcnRoutesRequest(Vpc_client) # 这里可使用ping返回结果 oper = &quot;normal&quot; if oper == &quot;normal&quot;: for BJ_id in BJ_RouteIds: BJ_DisableCcnRoutes(Vpc_client, BJ_id) for SH_id in SH_RouteIds: SH_EnableCcnRoutes(Vpc_client, SH_id) # SH_DisableCcnRoutes(Vpc_client, SH_id) else: for SH_id in SH_RouteIds: SH_DisableCcnRoutes(Vpc_client, SH_id) for BJ_id in BJ_RouteIds: BJ_EnableCcnRoutes(Vpc_client, BJ_id) 2、测试效果模拟异常时切换切换完毕时中间大概中断30秒左右。 最佳方案 如果网络不重叠，2个VPC之间使用对等连接、使用2个云联网然后分别加入对应VPC和IDC的专线，这样从IDC到云上可实现双活。例如IDC-上海中断，可通过IDC-北京再通过对等连接到上海。]]></content>
      <categories>
        <category>Case</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>腾讯云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker基础用法]]></title>
    <url>%2F2019%2F07%2F01%2FDocker%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Docker Architecture（docker体系结构） Docker daemon 守护进程 containers：容器 images：镜像 Docker client Docker registries 镜像仓库 Docker Images Docker镜像含有启动容器所需要的文件系统及其内容，因此其用于创建并启动docker容器 采用分层构建机制，最底层为bootfs，其之为rootfs bootfs：用于系统引导的文件系统，包括bootloader和kernel，容器启动完成后会被卸载以节约内存资源。 rootfs：位于bootfs上，表现为docker容器的根文件系统。docker中rootfs由内核挂载为“只读”模式，而后通过“联合挂载”技术额外挂载一个“可写”层。 安装docker 依赖环境 64 bits CPU Linux Kernel 3.10+ Docker Daemon systemctl start docker.service Docker Client docker [OPTIONS] COMMAND [arg…] 123456781.下载yum源https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo2.修改baseurl地址底行模式下：%s/https:\/\/download.docker.com\//https:\/\/mirrors.tuna.tsinghua.edu.cn\/docker-ce\//g3.查看程序包 yum repolist4.安装yum install -y docker-ce 配置文件 docker-ce： 配置文件：/etc/docker/daemon.json ,docker启动之前不存在可自行定义创建，启动之前就自动生成。123456789&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125;# 阿里云镜像&#123; &quot;registry-mirrors&quot;: [&quot;https://6ucotgoh.mirror.aliyuncs.com&quot;]&#125;# systemctl daemon-reload# systemcctl start docker 容器相关命令 docker image pull nginx:1.14-alpine : 下载镜像 docker run –name web1 -d nginx:1.14-alpine :运行容器 docker inspect web1 ：查看容器信息 docker container stop b1：停止容器 docker kill b1：强制关闭容器 docker rm b1：删除容器 docker rmi busybox：删除镜像 docker ps -a：查看容器状态 docker exec -it redis1 /bin/sh：交互式进入容器,并执行/bin/sh docker logs web1：查看容器日志 docker inspect mysql5.7 -f { {.Mounts} } ：查看容器指定key的键值如果不能自动补全docker命令，安装yum install -y bash-completion，然后退出当前终端重新连接。 Registry(repository and index) Repository 由某特定的docker镜像的所有迭代版本组成的镜像仓库。 一个Registry中可以存多个Repository Repository可分为“顶层仓库”和“用户仓库”，用户仓库名称格式为“用户名/仓库名” 每个仓库可以包含多个Tag(标签)，每个标签对应一个镜像。 Index 维护用户账户、镜像的校验以及公共命名空间的信息。 相当于为Registry提供了一个完成用户认证等功能的检索接口。 Docker Hub本地dckerfile变动发送到github，github推送到dockerhub自动构建为镜像。 Image Repositories：镜像仓库 Automated Builds：自动构建,dockerfile Webhooks：触发构建 Oraganizations：组织，创建工作组 GitHub and Bitbucket Integration：整合github、bitbucket 12# 下载镜像仓库指定镜像docker pull quay.io/coreos/flannel:v0.10.0-amd64 镜像生成方式 Dockerfile 基于容器制作 Docker Hub automated builds 基于容器制作123456789101112131415161、运行一个容器docker run --name b1 -it busybox (-it 交互式，-d 后台运行)2、修改容器如后台运行则可进入容器再操作docker exec -it b1 /bin/shmkdir -p /data/htmlvi /data/html/index.html3、提交镜像docker commit -p b1 (-p 暂停,防止数据有问题)docker image ls (REPOSITORY和TAG都是none,可以在commit时打上标签)4、给刚生成的打标签docker tag c7d5393e1bf2 liyk/boxhttp:v0.1再次打标签docker tag liyk/boxhttp:v0.1 liyk/boxhttp:latest5、运行命令打镜像docker commit -a &quot;Liyk &lt;liyk@anchnet.com&gt;&quot; -c &apos;CMD [&quot;/bin/httpd&quot;,&quot;-f&quot;,&quot;-h&quot;,&quot;/data/html&quot;]&apos; -p b1 liyk/httpd:v0.2 (-a 作者信息,-c 命令,-f 前台运行,-h 文件目录,-p 制作时暂停) 阿里云docker镜像仓库123456789101、控制台开通镜像仓库服务(设置仓库密码)2、创建镜像仓库，地域、命名空间(全局唯一)、仓库名称3、选择代码源，云code、github、私有gitlab等(需要绑定对应账号,提交代码后直接同步到镜像仓库)4、登录阿里云docker registry(用户名是阿里云账号全名，密码为开通服务时设置的密码)docker login --username=livcshiwo registry.cn-shanghai.aliyuncs.com5、从Registry中拉取镜像docker pull registry.cn-shanghai.aliyuncs.com/key1024/test:[镜像版本号]6、将镜像推送到Registrydocker tag [ImageId] registry.cn-shanghai.aliyuncs.com/key1024/test:[镜像版本号]docker push registry.cn-shanghai.aliyuncs.com/key1024/test:[镜像版本号] 镜像分享 镜像仓库：通过push到镜像仓库，需要镜像的再pull到服务器。 镜像打包：打包相关镜像，再scp到其他服务器。123456# 镜像打包docker save -o myimages.gz key1024/test:v0.1 key1024/test:v0.2# copy镜像scp myimages.gz node02:/data# load镜像docker load -i myimages.gz]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker容器网络]]></title>
    <url>%2F2019%2F07%2F01%2FDocker%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[6个命名空间User、Mount、Pid、UTS、Net、IPC 四种网络模式 host模式：使用–network=host指定 相当于Vmware中的桥接模式，与宿主机在同一个网络中，但没有独立IP地址。 容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。 容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。 bridge模式：使用–net=bridge指定 相当于Vmware中的Nat模式，容器使用独立network Namespace，并连接到docker0虚拟网卡（默认模式）。 通过docker0网桥以及Iptables nat表配置与宿主机通信。 Bridge模式是Docker默认的网络设置，此模式会为每一个容器分配Network Namespace、设置IP等，并将一个主机上的Docker容器连接到一个虚拟网桥上。 none模式：–net=none指定 容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。该模式关闭了容器的网络功能。 在以下两种情况下是有用的：容器并不需要网络（例如只需要写磁盘卷的批处理任务），overlay。 container模式：–net=container:NAME_or_ID指定 指定新创建的容器和已经存在的一个容器共享一个Network Namespace，而不是和宿主机共享。 新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。 两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过lo网卡设备通信。 1234# 查看网络模式详情docker network inspect bridge# 查看容器详情docker container inspect myMysql Bridged containers –hostname HOSTNAME选项为容器指定主机名。docker run --rm --net bridge --hostname bbox.test.com busybox:latest nslookup bbox.test.com –dns DNS_SERVER_IP 为容器指定所使用的dns服务器地址。docker run --rm --dns 172.16.0.1 busybox:latest nslookup docker.com –add-host HOSTNAME:IP 为容器指定本地主机名解析项。docker run --rm --dns 172.16.0.1 --add-host &quot;docker.com:172.16.0.10&quot; busybox:latest nslookup docker.com Docker端口暴露 -p 将指定容器端口映射至主机所有地址的一个动态端口 -p : 将容器端口映射至指定的主机端口 -p :: 将指定的容器端口映射至主机指定的动态端口 -p :: 将指定的容器端口映射至主机指定的端口 -P 大写的P，暴露所有端口(指暴露镜像里的全部端口) docker守护进程123456# 远程操作一个容器dockerd守护进程的C/S,其默认仅监听Unix socket格式地址，/var/run/docker.sock;如果使用TCP套接字，/etc/docker/daemon.json: &quot;hosts&quot;: [&quot;tcp://0.0.0.0:2375&quot;,&quot;unix:///var/run/docker.sock&quot;]也可向dockerd直接传递&quot;-H|--host&quot;选项。docker -H 172.17.0.3:2375 image ls 自定义docker012345678910111213# docker0桥网络属性信息：/etc/docker/daemon.json&#123; &quot;bip&quot;: &quot;192.168.1.1/24&quot;, &quot;fixed-cidr&quot;: &quot;10.20.0.0/16&quot;, &quot;fixed-cidr-v6&quot;: &quot;2001:db8::/64&quot;, &quot;mut&quot;: 1500, &quot;default-gateway&quot;: &quot;10.20.1.1&quot;, &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;, &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]&#125;# 核心选项为bip，即bridge ip之意，用于指定docker0桥自身的IP地址；其他地址可通过此地址计算得出。# 创建自定义网络docker network create -d bridge --subnet &quot;172.18.0.0/16&quot; --gateway &quot;172.18.0.1&quot; mybr0]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker存储卷]]></title>
    <url>%2F2019%2F07%2F01%2FDocker%E5%AD%98%E5%82%A8%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[Docker镜像由多个只读层叠加而成，启动容器时Docker会加载只读镜像层并在镜像栈顶部添加一个读写层。 如果运行中的容器修改了现有的一个已存在的文件，那该文件将会从读写层下面的只读层复制到读写层，该文件只读版本仍然存在。只是已经被读写层中该文件的副本所隐藏，此即“写时复制(COW)”机制。 Data Volume 关闭并重启容器其数据不受影响，但删除Docker容器则其更改将会全部丢失。 存在的问题： 存储于联合文件系统中，不易于宿主机访问； 容器间数据共享不便 删除容器其数据会丢失。 解决办法：卷(volume) 卷 是容器上的一个或多个目录，此类目录可绕过联合文件系统，与宿主机上的某种目录“绑定(关联)” Volume types Bind-mount volume：宿主机和容器上2个已知路径建立联系，必须双方都指定。 Docker-managed volume：指定容器挂载目录，存储上由docker自动指定挂载目录(/var/lib/docker/vfs/dir/&lt;容器长id&gt;)，只用指定容器目录，但是宿主机上是随机生成的不能指定。 容器中使用volumes Bind-mount volume docker run -it -v HOSTDIR:VOLUMEDIR –name bbox1 busybox docker inspect -f { {.Mounts} } bbox1 # 过滤数据 Docker-managed volume docker run -it –name bbox2 -v /data busybox docker inspect -f { {.Mounts} } bbox2 docker inspect -f { {.NetworkSettings.IPAddress} } bbox2 Sharing volumes 多个容器的卷使用同一个主机目录 docker run -it –name c1 -v /data/volumes/v1:/data busybox docker run -it –name c2 -v /data/volumes/v1:/data busybox 复制使用其他容器的卷，为docker run 命令使用–volumes-from选项 docker run -it –name b1 -v /data/volumes/v2:/data busybox docker run -it –name b2 –volumes-from b1 busybox]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Harbor安装]]></title>
    <url>%2F2019%2F07%2F01%2FHarbor%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Harbor正是一个用于存储Docker镜像的企业级Registry服务。 Harbor核心组件 Proxy：他是一个nginx的前端代理，代理Harbor的registry,UI, token等服务。 db：负责储存用户权限、审计日志、Dockerimage分组信息等数据。 UI：提供图形化界面，帮助用户管理registry上的镜像, 并对用户进行授权。 jobsevice：jobsevice是负责镜像复制工作的，他和registry通信，从一个registry pull镜像然后push到另一个registry，并记录job_log。 Adminserver：是系统的配置管理中心附带检查存储用量，ui和jobserver启动时候回需要加载adminserver的配置。 Registry：镜像仓库，负责存储镜像文件。 Log：为了帮助监控Harbor运行，负责收集其他组件的log，供日后进行分析。 安装和配置安装要求 最小配置：2核、4G内存、40G硬盘 Docker引擎：17.03.0-ce +或更高版本 Docker compose：1.18.0或更高版本 安装Openssl：为Harbor生成证书和密钥 网络端口 端口 协议 描述 443 HPPTS Harbor端口和核心API将接受此端口上的https协议请求，此端口可以在配置文件中更改 8443 HTTPS 只有在启用“公证”时才需要连接到Dock的Docker Content Trust服务，此端口可以在配置文件中更改 80 HTTP Harbor端口和核心API将接受此端口上的http协议请求 安装步骤1.下载安装程序 12wget https://storage.googleapis.com/harbor-releases/release-1.8.0/harbor-offline-installer-v1.8.1.tgztar -zxvf harbor-online-installer-v1.8.1.tgz 2.配置harbor.yml有两类参数，必需参数和可选参数 必需参数： hostname：目标主机的主机名，用于访问Portal和注册表服务。例如192.168.1.10或reg.yourdomain.com。不要使用localhost或127.0.0.1作为主机名 - 外部客户端需要访问注册表服务！ data_volume：本地存储harbor数据的位置 harbor_admin_password：管理员的初始密码。此密码仅在Harbor首次启动时生效。之后，将忽略此设置，并且应在Portal中设置管理员密码。请注意，默认用户名/密码为admin / Harbor12345。 database：与本地数据库相关的配置，password：用于db_auth的PostgreSQL数据库的root密码。 jobservice：jobservice相关服务，max_job_workers：作业服务中的最大复制工作者数。对于每个映像复制作业，工作程序将存储库的所有标记同步到远程目标。增加此数量可以在系统中执行更多并发复制作业。但是，由于每个工作者都消耗一定量的网络/ CPU / IO资源，请根据主机的硬件资源仔细选择该属性的值。 log：log相关的url； 3.运行install.sh安装并启动Harbor 1234567891011121314151617181920212223# 安装docker1.下载yum源https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo2.修改baseurl地址底行模式下：%s/https:\/\/download.docker.com\//https:\/\/mirrors.tuna.tsinghua.edu.cn\/docker-ce\//g3.查看程序包 yum repolist4.安装yum install -y docker-ce5.配置文件：/etc/docker/daemon.json ,docker启动之前不存在可自行定义创建，启动之前就自动生成。&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125;# 阿里云镜像&#123; &quot;registry-mirrors&quot;: [&quot;https://6ucotgoh.mirror.aliyuncs.com&quot;]&#125;# systemctl daemon-reload# systemcctl start docker# 安装docker-compose，如果提前安装过忽略此步骤yum install docker-compose -y # 安装harbor./install.sh]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx日志切割]]></title>
    <url>%2F2019%2F07%2F01%2Fnginx%E6%97%A5%E5%BF%97%E5%88%87%E5%89%B2%2F</url>
    <content type="text"><![CDATA[nginx日志自动切割有利于分析查看日志 1.日志配置1234567access.log 记录哪些用户,哪些页面以及用户浏览器,IP等访问信息；error.log 记录服务器错误的日志；配置日志存储路径location / &#123; access_log /usr/local/nginx/logs/access.log; error_log /usr/local/nginx/logs/error.log; &#125; nginx日志配置方法，默认已自动设置 2.日志切割 12345678#!/bin/bash LOGS_PATH=/var/log/nginx/ YESTERDAY=$(date -d yesterday +&quot;%Y%m%d&quot;) #,%Y-%m-%d等于%Fmv $&#123;LOGS_PATH&#125;/access.log $&#123;LOGS_PATH&#125;/logs/access_$&#123;YESTERDAY&#125;.log #mv $&#123;LOGS_PATH&#125;/error.log $&#123;LOGS_PATH&#125;/error_$&#123;YESTERDAY&#125;.log ## 向 Nginx 主进程发送 USR1 信号。USR1 信号是重新打开日志文件 kill -USR1 `cat $&#123;LOGS_PATH&#125;/nginx.pid` #kill -USR1 `cat /var/log/nginx/nginx.pid` 3.设置定时任务 1234crontab -e每天凌晨1分执行01 0 * * * /var/log/nginx/splitLog.sh重启定时任务 补充方式一： nginx cronolog日志分割配置文档，根据下面方法，每分钟分割一次NGINX访问日志。123456781.nginx日志配置 access_log access_log /data/access_log_pipe main;2.先创建一个命名管道mkfifo /www/log/access_log_pipe3.配置cronolog：nohup cat /data/access_log_pipe | /usr/local/sbin/cronolog /data/log/domain.access_%Y%m%d%H%M.log &amp;4.启动Nginx/usr/local/nginx/sbin/nginx 123456789注意：cronolog必须在nginx启动前启动没有安装cronolog的话，需要先安装wget http://cronolog.org/download/cronolog-1.6.2.tar.gztar zxvf cronolog-1.6.2.tar.gzcd cronolog-1.6.2./configure makemake install 方式二： 定时任务中每小时添加定时任务，执行一下脚本，可以实现小时日志分割。12345log_dir=&quot;/var/log/nginx&quot;date_dir=`date +%Y/%m/%d/%H`/bin/mkdir -p $&#123;log_dir&#125;/$&#123;date_dir&#125; &gt; /dev/null 2&gt;&amp;1/bin/mv $&#123;log_dir&#125;/access.log $&#123;log_dir&#125;/$&#123;date_dir&#125;/access.logkill -USR1 `cat /opt/nginx/logs/nginx.pid` 方式三： 使用logrotate做nginx日志轮询12345678910logrotate看名字就知道是专门做日志轮询的，只把任务配置放在/etc/logrotate.d/下，任务就会自动完成，而且无需安装，系统自带，比较推荐使用.vim /etc/logrotate.d/nginx /usr/local/nginx/logs/www.willko.cn.log /usr/local/nginx/logs/nginx_error.log &#123; notifempty daily sharedscripts postrotate /bin/kill -USR1 `/bin/cat /usr/local/nginx/nginx.pid` endscript &#125; 多个日志以空格分开，notifempty 如果日志为空则不做轮询daily 每天执行一次postrotate 日志轮询后执行的脚本这样，每天都会自动轮询，生成nginx.log.1-n]]></content>
      <categories>
        <category>WEB</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下的jq命令处理json数据]]></title>
    <url>%2F2019%2F07%2F01%2FLinux%E4%B8%8B%E7%9A%84jq%E5%91%BD%E4%BB%A4%E5%A4%84%E7%90%86json%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[jq命令可以过滤json格式数据1234安装 https://stedolan.github.io/jq/wget -O jq https://github.com/stedolan/jq/releases/download/jq-1.5/jq-linux64chmod +x ./jqcp jq /usr/bin 操作演示cat test.json | jq cat 1.json |jq -r &#39;.timeDelay[].duration&#39; 过滤出duration里的数据 1234cat 1.json |jq -r &apos;.timeDelay[] |select (.url | contains(“http:/as/index”))&apos;contains包含这个值的全部匹配cat 1.json |jq -r &apos;.timeDelay[] |select (.url == “http:/as/index”)&apos;== 等于这个值的匹配 有个弊端就是不支持key是数字的 1234567891011# 批量过滤数据脚本#!/bin/bashcat api_url.txt |while read linedo id=$(echo $line |awk -F&apos;/&apos; &apos;&#123;print $2&quot;-&quot;$3&#125;&apos;) if [ $id == &quot;-&quot; ];then id=1 fi# cat 1.json |jq -r &apos;.timeDelay[] |select (.url | contains(&quot;&apos;$line&apos;&quot;))&apos; &gt; /data/script/api_url/$&#123;id&#125;.json cat 1.json |jq -r &apos;.timeDelay[] |select (.url == &quot;&apos;$line&apos;&quot;)&apos; &gt; /data/script/api_url/$&#123;id&#125;.jsondone]]></content>
      <categories>
        <category>system</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker部署lnmp]]></title>
    <url>%2F2019%2F06%2F15%2FDocker%E9%83%A8%E7%BD%B2lnmp%2F</url>
    <content type="text"><![CDATA[安装docker 安装 123456781.下载yum源https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo2.修改baseurl地址底行模式下：%s/https:\/\/download.docker.com\//https:\/\/mirrors.tuna.tsinghua.edu.cn\/docker-ce\//g3.查看程序包 yum repolist4.安装yum install -y docker-ce 配置 12345678910配置文件：/etc/docker/daemon.json ,docker启动之前不存在可自行定义创建，启动之前就自动生成。&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125;# 阿里云镜像&#123; &quot;registry-mirrors&quot;: [&quot;https://6ucotgoh.mirror.aliyuncs.com&quot;]&#125;# systemctl daemon-reload# systemcctl start docker 下载需要的镜像123docker pull nginx:alpinedocker pull php:5.6-fpmdocker pull mysql:5.7 相关部署 启动php 1234docker run --name myphp -v /data/nginx/www:/www -d php:5.6-fpm# --name myphp :将容器命名为 myphp# -v /data/nginx/www:/www :将主机中项目的目录/data/nginx/www 挂载到容器的/www# -d :后台运行 添加nginx配置文件 12345678910111213141516171819202122232425262728# 创建 /data/nginx/conf/conf.d 目录：mkdir -p /data/nginx/conf/conf.d在/data/nginx/conf/conf.d/test-php.conf 文件，内容如下：server &#123; listen 80; server_name localhost; location / &#123; root /usr/share/nginx/html; index index.html index.htm index.php; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root /usr/share/nginx/html; &#125; location ~ \.php$ &#123; fastcgi_pass 172.17.0.4:9000; # 这里为php容器的ip fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /www/$fastcgi_script_name; include fastcgi_params; &#125;&#125;# fastcgi_pass ：填写php器的ip，使用docker inspect myphp -f `&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;`查看IP 启动nginx 1docker run --name mynginx -p 80:80 -d -v /data/nginx/www:/usr/share/nginx/html:ro -v /data/nginx/conf/conf.d:/etc/nginx/conf.d:ro --link myphp5.6:php nginx:alpine 测试php 12345# 在/data/nginx/www目录下创建test-php.php，代码如下：&lt;?phpecho phpinfo();?&gt;# 浏览器访问测试：IP/test-php.php 启动mysql 1docker run --name myMysql -P -e MYSQL_ROOT_PASSWORD=Xxzx@789 -d mysql 测试php连接mysql 12345678910111213141516171819&lt;?php$dbms=&apos;mysql&apos;; //数据库类型$host=&apos;172.17.0.2&apos;; //数据库主机名,此处写mysql 容器的名字$dbport = &apos;3306&apos;;$dbName=&apos;emlog&apos;; //使用的数据库$user=&apos;root&apos;; //数据库连接用户名$pass=&apos;X****&apos;; //对应的密码$dsn=&quot;$dbms:host=$host;port=$dbport;dbname=$dbName&quot;;try &#123; $dbh = new PDO($dsn, $user, $pass); //初始化一个PDO对象 echo &quot;successful!&lt;br/&gt;&quot;; //你还可以进行一次搜索操作 // foreach ($dbh-&gt;query(&apos;SELECT * from user&apos;) as $row) &#123; // print_r($row); //你可以用 echo($GLOBAL); 来看到这些值 // &#125; $dbh = null;&#125; catch (PDOException $e) &#123; die (&quot;Error!: &quot; . $e-&gt;getMessage() . &quot;&lt;br/&gt;&quot;);&#125; docker容器安装vim等命令 1234567# 进入容器docker exec -it 容器名 /bin/bash（或者/bin/sh）# 查看容器的系统版本cat /etc/issue# 此处以ubuntu为例,先更新软件包，否则安装可能会提示Unable to locate package vimapt-get updateapt-get install vim php连接mysql报错：could not find driver 12345678910# 默认官方php是没添加支持mysql，需自行安装配置1、进入php容器docker exec -it myphp /bin/bash2、进入安装扩展目录下whereis php # 查看在/usr/local/bin下# 安装扩展 ：docker-php-ext-install ./docker-php-ext-install pdo pdo_mysql./docker-php-ext-install mysqli3、查看php.iniphp --ini 安装gd扩展：验证码要用 1234567891011121314151、进入php容器docker exec -it myphp /bin/bash2、安装依赖apt-get install libpng-dev3、进入安装扩展目录./docker-php-ext-install -j$(nproc) gd4、重启php容器，测试gd&lt;?if(extension_loaded(&apos;gd&apos;)) &#123; echo &apos;您可以使用gd&lt;br&gt;&apos;; foreach(gd_info() as $cate=&gt;$value) echo &quot;$cate: $value&lt;br&gt;&quot;;&#125; else echo &apos;没安装gd扩展!&apos;?&gt;]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows下通过bat脚本自动重启apache服务]]></title>
    <url>%2F2019%2F06%2F14%2Fwindows%E4%B8%8Bbat%E8%84%9A%E6%9C%AC%E8%87%AA%E5%8A%A8%E9%87%8D%E5%90%AFApache%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[问题描述 客户使用的集成环境phpstudy，上面运行的是php+apahce+mysql，经常无故apache异常导致网站无法打开，需要重启apache服务恢复。由于不方便变更基础环境，故考虑使用bat脚本自动检测网站是否正常判断是否需要重启apache服务。 准备工作12341、由于借助curl命令测试网站是否正常，需提前安装配置好curl命令。https://curl.haxx.se/download.html#Win64下载对应的版本安装，并配置好环境变量。(在cmd中能使用curl命令)2、最好将apache注册为系统服务，这样方便使用net重启服务。否则就要指定目录去重启。（注册系统服务推荐使用nssm） 注册系统服务12345678910# 如果已是系统服务跳过此步骤，比如phpstudy上可注册为系统服务1、下载，解压安装官网：http://nssm.cc/download根据操作系统选择32位或64位nssm，在该目录启动命令行窗口，建议写入path环境变量2、服务注册（此处是之前注册logstash的截图）nssm install logstash接下来会弹出一个框，在path处选择启动logstash的start.bat点击Install service即可填写应用程序的对应路径、设置Service name。最后单击install service按钮，执行安装。 编写脚本12345678910111213141516::Auto restart apache@echo offset url=http://www.gc1999.comecho %url%for /f %%z in (&apos;curl -so /dev/null -w %%&#123;http_code&#125; %url%&apos;) do (set result=%%zecho %%z)if %result% NEQ 200 (::echo %date%%time% %url% 无法打开 错误代码 %result% &gt;&gt;C:\log\%date:~0,4%%date:~5,2%%date:~8,2%ERROR.lognet stop apache2anet start apache2a) else (::echo %date%%time% %url% 网页可以打开 代码 %result% &gt;&gt;C:\log\%date:~0,4%%date:~5,2%%date:~8,2%SUCCESS.logecho %date%%time% %url% 网页可以打开 代码 %result%) 设置任务计划定期执行自定义任务计划，重复执行检测]]></content>
      <categories>
        <category>system</category>
        <category>windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
</search>
